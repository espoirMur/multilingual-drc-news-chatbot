{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Question answering system\n",
    "\n",
    "For  this work , we will build our question answering system , we will leverage the [deepset framework]() to build the components of our system.\n",
    "\n",
    "Here are the followign components of our system:\n",
    "-  The index store \n",
    "- The document store \n",
    "- The search pipeline with a Retrieval and a Reader model.\n",
    "\n",
    "We will be leveraging the tutorials provided by deepstack to build our system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this work we will leverage [this  tutorial:](https://github.com/deepset-ai/haystack/blob/master/tutorials/Tutorial6_Better_Retrieval_via_DPR.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the dense passage retrieval\n",
    "\n",
    "To build the dataset for the dense passage retrieval , we will be using the approach suggested by [this tutorial](https://huggingface.co/etalab-ia/dpr-question_encoder-fr_qa-camembert) which use the cambert model .\n",
    "\n",
    "For each question , we have a single positive context , the paragraph where the answer to the question is located and n hard negavives contexts that are the the top - k canditates taht does not contain the answer, to the question. to retrieve the negative context they will use the bm25 retrieval model.\n",
    "\n",
    "Before training the retrieval model we will have to build the document store and save the document as units of retrieval to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = Path.cwd().joinpath(\"data\")\n",
    "assert DATA_PATH.exists(), \"the data path does not exist\"\n",
    "TEXT_DATA_FOLDER = DATA_PATH.joinpath(\"corpus\", \"drc-news-txt\")\n",
    "assert TEXT_DATA_FOLDER.exists(), \"the text data folder does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = DATA_PATH.joinpath(\"corpus\", \"raw\", 'drc-news-raws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file_path, names=[\"content\", \"posted_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140638, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>posted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les membres de la Commission tarifaire viennen...</td>\n",
       "      <td>2022-09-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les membres de la Commission tarifaire so...</td>\n",
       "      <td>2022-04-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vodacom Congo vient de signer un partenariat a...</td>\n",
       "      <td>2022-04-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le sélectionneur des Léopards de la RDC, Hectó...</td>\n",
       "      <td>2022-03-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le protocole d’accord était déjà signé entre l...</td>\n",
       "      <td>2022-11-05 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content            posted_at\n",
       "0  Les membres de la Commission tarifaire viennen...  2022-09-05 00:00:00\n",
       "1       Les membres de la Commission tarifaire so...  2022-04-05 00:00:00\n",
       "2  Vodacom Congo vient de signer un partenariat a...  2022-04-23 00:00:00\n",
       "3  Le sélectionneur des Léopards de la RDC, Hectó...  2022-03-05 00:00:00\n",
       "4  Le protocole d’accord était déjà signé entre l...  2022-11-05 00:00:00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.fillna(value=\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
      "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n",
      "WARNING - haystack -  Object '__file__' is imported through a deprecated path. Please check out the docs for the new import path.\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import TextConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.schema import Document\n",
    "from secrets import token_hex\n",
    "\n",
    "# @Todo: this is not working now , it was supposed to save the document to dataframe\n",
    "def get_document_from_text(row):\n",
    "    \"\"\"numpy row with the text and the date of the post\n",
    "\n",
    "    Args:\n",
    "        row (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    text = row[0].replace(u'\\xa0', u' ')\n",
    "    for paragraph in text.split(\"   \"):\n",
    "        if not paragraph.strip():  # skip empty paragraphs\n",
    "            continue\n",
    "        return Document(content=paragraph, meta={\"posted_at\":row[1] if row[1] else \"\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import TextConverter, PDFToTextConverter, DocxToTextConverter, PreProcessor\n",
    "from haystack.utils import convert_files_to_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = data.sample(1000).apply(get_document_from_text, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = all_docs.dropna().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.errors import HaystackError\n",
    "from haystack.schema import Document\n",
    "from typing import List, Optional, Generator, Set, Union\n",
    "from copy import deepcopy\n",
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "class CustomPreProcessor(PreProcessor):\n",
    "    def __init__(self, custom_preprocessor=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.custom_preprocessor = custom_preprocessor\n",
    "    def clean(\n",
    "        self,\n",
    "        document: Union[dict, Document],\n",
    "        clean_whitespace: bool,\n",
    "        clean_header_footer: bool,\n",
    "        clean_empty_lines: bool,\n",
    "        remove_substrings: List[str],\n",
    "        id_hash_keys: Optional[List[str]] = None,\n",
    "    ) -> Document:\n",
    "        \"\"\"\n",
    "        \n",
    "        Perform document cleaning on a single document and return a single document. This method will deal with whitespaces, headers, footers\n",
    "        and empty lines. Its exact functionality is defined by the parameters passed into PreProcessor.__init__().\n",
    "        \"\"\"\n",
    "        if id_hash_keys is None:\n",
    "            id_hash_keys = self.id_hash_keys\n",
    "\n",
    "        if isinstance(document, dict):\n",
    "            document = Document.from_dict(document, id_hash_keys=id_hash_keys)\n",
    "\n",
    "        # Mainly needed for type checking\n",
    "        if not isinstance(document, Document):\n",
    "            raise HaystackError(\"Document must not be of type 'dict' but of type 'Document'.\")\n",
    "        text = document.content\n",
    "        text = self.custom_preprocessor(text)\n",
    "        if clean_header_footer:\n",
    "            text = self._find_and_remove_header_footer(\n",
    "                text, n_chars=300, n_first_pages_to_ignore=1, n_last_pages_to_ignore=1\n",
    "            )\n",
    "\n",
    "        if clean_whitespace:\n",
    "            lines = text.splitlines()\n",
    "\n",
    "            cleaned_lines = []\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                cleaned_lines.append(line)\n",
    "            text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "        if clean_empty_lines:\n",
    "            text = re.sub(r\"\\n\\n+\", \"\\n\\n\", text)\n",
    "\n",
    "        for substring in remove_substrings:\n",
    "            text = text.replace(substring, \"\")\n",
    "\n",
    "        if text != document.content:\n",
    "            document = deepcopy(document)\n",
    "            document.content = text\n",
    "\n",
    "        return document\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.utils import deaccent\n",
    "from unicodedata import normalize as unicode_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_point(document):\n",
    "    \"\"\"replace the point with the wwt.www with space point before tokenizing the document .\n",
    "    TOdos : this may have a a downside when the point is in the middle of a words\n",
    "    Args:\n",
    "        document (_type_): _description_\n",
    "    \"\"\"\n",
    "    result = re.sub(r\"(\\S)\\.(\\S)\", r\"\\1 . \\2\", document)\n",
    "    return result\n",
    "\n",
    "def replace_website_name(document):\n",
    "    \"\"\"sometimes the doucment has the name politico.cd or 7sur7.cd or actualite.cd, we would like to replace them by the \n",
    "    actual name of the website. before proper cleaning\n",
    "\n",
    "    Args:\n",
    "        document (_type_): _description_\n",
    "    \"\"\"\n",
    "    # @TODO : not sure if this will work but , way better replace by the first line of match.\n",
    "    \n",
    "    result = re.sub(r\"7SUR7.CD|politico.cd|actualite.cd|mediacongo.net\", r\"SITE_WEB\", document, flags=re.IGNORECASE)\n",
    "    return result\n",
    "\n",
    "def remove_accents(document):\n",
    "    input_without_accent = deaccent(document)\n",
    "    return input_without_accent\n",
    "\n",
    "def pre_clean_document(document):\n",
    "    \"\"\"pre clean the document by removing the accents and replacing the point with the wwt.www with space point before tokenizing the document .\n",
    "    TOdos : this may have a a downside when the point is in the middle of a words\n",
    "    and any other side of cleaning that we want to do .\n",
    "    Args:\n",
    "        document (_type_): _description_\n",
    "    \"\"\"\n",
    "    result = remove_accents(document)\n",
    "    result =  replace_website_name(result)\n",
    "    result = replace_point(result)\n",
    "    result = re.sub(r\"This post has already been read \\d+ times!\", \"\", result) # remove unwanted text\n",
    "    result = unicode_normalize(\"NFKD\", result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_doc = \"\"\"\n",
    "Une motion de defiance a ete deposee au cabinet de la presidente de l'Assemblee provinciale du Maniema contre le vice-gouverneur Jean-Pierre Amadi, le mardi 30 mars dernier.16 parmi les 17 deputes provinciaux presents a Kindu, chef-lieu de la province du Maniema, ont appose leurs signatures sur ladite motion depuis le 27 mars 2021.Selon ce document consulte par 7SUR7.CD, Jean-Pierre Amadi Lubenga est reproche de plusieurs griefs dont le « refus d'obtemperer aux instructions de la hierarchie » pendant qu'il etait gouverneur de province a l'interim et le detournement des deniers publics.\n",
    "comme signale a politico.cd sur notre site POLITICO.CD et puis ensuite sur actualite.cd et sur notre site mediacongo.net\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nUne motion de defiance a ete deposee au cabinet de la presidente de l'Assemblee provinciale du Maniema contre le vice-gouverneur Jean-Pierre Amadi, le mardi 30 mars dernier.16 parmi les 17 deputes provinciaux presents a Kindu, chef-lieu de la province du Maniema, ont appose leurs signatures sur ladite motion depuis le 27 mars 2021.Selon ce document consulte par SITE_WEB, Jean-Pierre Amadi Lubenga est reproche de plusieurs griefs dont le « refus d'obtemperer aux instructions de la hierarchie » pendant qu'il etait gouverneur de province a l'interim et le detournement des deniers publics.\\ncomme signale a SITE_WEB sur notre site SITE_WEB et puis ensuite sur SITE_WEB et sur notre site SITE_WEB\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_website_name(text_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 250/997 [00:00<00:01, 546.89docs/s]WARNING - haystack.nodes.preprocessor.preprocessor -  One or more sentence found with word count higher than the split length.\n",
      "100%|██████████| 997/997 [00:01<00:00, 696.91docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files_input: 997\n",
      "n_docs_output: 2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessor = CustomPreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_respect_sentence_boundary=True,\n",
    "    language=\"fr\",\n",
    "    custom_preprocessor=pre_clean_document,\n",
    ")\n",
    "\n",
    "\n",
    "docs = preprocessor.process(all_docs)\n",
    "\n",
    "print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document: {'content': 'Lambert Mende, ministre de la Communication de la Republique Democratique du Congo (RDC) a evoque jeudi la possibilite d‟un referendum en vue de changer certains articles de la Constitution. Il s‟exprimait devant la presse en reponse aux critiques formulees par la conference episcopale nationale du Congo (CENCO) qui a appele le gouvernement a ne pas modifier la Constitution pour augmenter le nombre de mandats permis au chef de l‟Etat . \"Au moins on n‟a pas conteste aux Ecossais et a ceux qui vivent en Ecosse le droit de se prononcer, pourquoi on veut contester au Congolais le droit de se prononcer ? \", a-t-il lance lors de son intervention. Lambert Mende affirme que l‟idee d‟un referendum vient de la commission electorale nationale independante (CENI). Cet eventuellement changement de la Constitution ne concernerait que certains articles dont le plus significatif est l‟article 197 qui concerne le mode de scrutin des elections provinciales . L\\'article 220 au centre des debatsL\\'objectif etant de passer au mode indirect pour faire des economies. Mais Lambert Mende n\\'exclut pas pour autant un referendum sur l‟article au centre de tous les regards.', 'content_type': 'text', 'score': None, 'meta': {'posted_at': '', '_split_id': 0}, 'embedding': None, 'id': 'f42a9583173034ac90d79ddcb200a4c3'}>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/.venv/lib/python3.9/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.16/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "INFO - haystack.document_stores.elasticsearch -  Index 'drc-news' deleted.\n",
      "INFO - haystack.document_stores.elasticsearch -  Index 'label' deleted.\n"
     ]
    }
   ],
   "source": [
    "document_store = ElasticsearchDocumentStore(index=\"drc-news\", recreate_index=True, analyzer=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval\n",
    "\n",
    "With the document store in place , the document store has all the document in it , let build a retriever model that use BM25 to retrieve the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_query_template = \"\"\"\n",
    "{\n",
    "  \"query\": {\n",
    "    \"boosting\": {\n",
    "      \"positive\": {\n",
    "        \"match\": {\n",
    "          \"content\": ${query}\n",
    "        }\n",
    "      },\n",
    "      \"negative\": {\n",
    "        \"match\": {\n",
    "          \"content\": ${name_to_not_match}\n",
    "        }\n",
    "      },\n",
    "      \"negative_boost\": 0.5\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"query\": {\n",
      "    \"boosting\": {\n",
      "      \"positive\": {\n",
      "        \"match\": {\n",
      "          \"content\": ${query}\n",
      "        }\n",
      "      },\n",
      "      \"negative\": {\n",
      "        \"match\": {\n",
      "          \"content\": ${name_to_not_match}\n",
      "        }\n",
      "      },\n",
      "      \"negative_boost\": 0.5\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(custom_query_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever(document_store=document_store, all_terms_must_match=True, custom_query=custom_query_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"le president de la Republique democratique du congo?\"\n",
    "answer = \"Felix Tshisekedi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_negative_context(\n",
    "    retriever: BM25Retriever, question: str, answer: str, n_ctxs: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    given the question and the answer query the Elastic search document store and return the hard negative context to the question\n",
    "    \"\"\"\n",
    "\n",
    "    documents = bm25_retriever.retrieve(query=question, top_k=10, filters={\"name_to_not_match\": answer})\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Document: {'content': 'Le President National Statutaire et Autorite Morale de l’ADFC-A, le Senateur Professeur Modeste BAHATI LUKWEBO, invite les cadres et militants du Regroupement AFDC-A a participer a toutes les manifestations pacifiques visant a defendre la paix, la democratie, la bonne gouvernance, l’Etat de droit et les elections transparentes en Republique Democratique du Congo. DECLARATION DE LA CONFERENCE DES PRESIDENTS DU REGROUPEMENT POLITIQUE AFDC-A SUR LA SITUATION POLITIQUE ET SECURITAIRE DU PAYSDepuis la prolongation inconstitutionnelle de la session ordinaire du Parlement de la Republique Democratique du Congo, plusieurs initiatives democraticides, liberticides et subversives ont ete alignees par le FCC, s’appuyant sur la majorite numerique au Parlement et profitant de l’Etat d’urgence sanitaire pour s’assurer a l’avance de la fausse victoire electorale, proteger les membres du FCC de toute poursuite judiciaire et vider la justice congolaise de son pouvoir constitutionnel .', 'content_type': 'text', 'score': 0.7464917124423509, 'meta': {'posted_at': '', '_split_id': 0}, 'embedding': None, 'id': 'b5d9f7e304edbd1b26a915d187bf97fe'}>,\n",
       " <Document: {'content': 'Selon Claude Misare, president de la societe civile d’Uvira, une ville et un territoire de la province du Sud-Kivu en Republique democratique du Congo, l’on compte a present cinq morts dont quatre enfants d’une meme famille apres des fortes pluies samedi . «  » explique-t-il . « « , ajoute le president de la societe civile . Selon lui, la principale cause de ces degats reste la defaillance de « « .', 'content_type': 'text', 'score': 0.7364710114796169, 'meta': {'posted_at': '2018-05-06 14:58:30', '_split_id': 0}, 'embedding': None, 'id': '2a40c31a783d3dbeca61118425fcf37'}>,\n",
       " <Document: {'content': 'Le President National Statutaire et Autorite Morale de l’ADFC-A, le Senateur Professeur Modeste BAHATI LUKWEBO, invite les cadres et militants du Regroupement AFDC-A a participer a toutes les manifestations pacifiques visant a defendre la paix, la democratie, la bonne gouvernance, l’Etat de droit et les elections transparentes en Republique Democratique du Congo . Fait a Bruxelles par teleconference, le 05 juillet 2020Senateur Professeur Modeste Bahati Lukwebo President National Statutaire et Autorite Morale de l’AFDC-A', 'content_type': 'text', 'score': 0.735545974237315, 'meta': {'posted_at': '', '_split_id': 4}, 'embedding': None, 'id': '8bac9ac2d03734cf3963016727afcf9c'}>,\n",
       " <Document: {'content': 'Adoptee par le Conseil de securite a sa 4076e seance, le 30 novembre 1999\\nLe Conseil de securite,\\nRappelant ses resolutions 1234 (1999) du 9 avril 1999, 1258 (1999) du 6 aout 1999 et 1273 (1999) du 5 novembre 1999 ainsi que les declarations faites par son President les 31 aout 1998 (S/PRST/1998/26), 11 decembre 1998 (S/PRST/1998/36) et 24 juin 1999 (S/PRST/1999/17),\\nAyant a l’esprit les buts et principes inscrits dans la Charte des Nations Unies et la responsabilite principale qui lui incombe en matiere de maintien de la paix et de la securite internationales,\\nReaffirmant la souverainete, l’integrite territoriale et l’independance politique de la Republique democratique du Congo et de tous les Etats de la region,\\nReaffirmant egalement que l’Accord de cessez-le-feu de Lusaka (S/1999/815) represente la base la plus viable pour la resolution du conflit en Republique democratique du Congo, et notant le role que l’Organisation des Nations Unies y est appelee a jouer dans le respect du cessez-le-feu,\\nSe declarant preoccupe par les violations presumees de l’Accord de cessez-le-feu et exhortant toutes les parties a s’abstenir de toute declaration ou action qui risquerait de compromettre le processus de paix,\\nSoulignant les responsabilites des signataires pour ce qui est de l’application de l’Accord de cessez-le-feu, et engageant ceux-ci a permettre et a faciliter le deploiement integral des officiers de liaison des Nations Unies et du personnel necessaire a l’execution de leur mandat dans l’ensemble du territoire de la Republique democratique du Congo,\\nAccueillant avec satisfaction les promesses d’appui faites a la Commission militaire mixte par certains Etats et organisations, et engageant les autres a contribuer, avec les signataires de l’Accord de cessez-le-feu, au financement de cet organe,\\nJugeant preoccupante la situation humanitaire en Republique democratique du Congo et engageant tous les Etats Membres a repondre aux appels humanitaires globaux en cours et futurs,\\nSe declarant preoccupe par les consequences graves du conflit pour la securite et le bien-etre de la population civile sur tout le territoire de la Republique democratique du Congo,\\nSe declarant egalement preoccupe par l’incidence prejudiciable du conflit sur la situation des droits de l’homme dans la Republique democratique du Congo, en particulier dans l’est du pays, ainsi que par les violations des droits de l’homme et du droit international humanitaire qui continuent d’etre commises sur tout le territoire de la Republique democratique du Congo,\\nAyant examine les recommandations du Secretaire general contenues dans son rapport du 1er novembre 1999 (S/1999/1116),\\nReaffirmant qu’il est important que soit menee a bien la mission de l’equipe d’evaluation technique depechee en Republique democratique du Congo pour evaluer la situation, preparer un eventuel deploiement ulterieur de l’Organisation des Nations Unies dans le pays et obtenir des parties au conflit des garanties fermes quant a la securite et a la liberte de mouvement du personnel de l’Organisation des Nations Unies et du personnel associe,\\nRappelant les principes pertinents enonces dans la Convention sur la securite du personnel des Nations Unies et du personnel associe, adoptee le 9 decembre 1994,\\nSoulignant qu’il est important que le personnel militaire de liaison des Nations Unies soit entierement deploye conformement a la resolution 1258 (1999),\\n1.', 'content_type': 'text', 'score': 0.7275780619012074, 'meta': {'posted_at': '', '_split_id': 2}, 'embedding': None, 'id': '69fcb0a8f7df939e9c390bfd9c7d3795'}>,\n",
       " <Document: {'content': \"Intervenaient egalement au cours de cette conference, Monsieur le Ministre de l'Emploi, du travail et de la prevoyance sociale, Modeste BAHATI LUKWEBO, Monsieur Jean-Christophe MAURIN, Directeur de l'Agence francaise de developpement (AFD), Monsieur Joseph KAMGA, President de l'Association pour l'Efficacite du Droit et de la Justice dans l'espace OHADA (AEDJ) et Madame Eliane MUNKENI, Presidente de la Commission Nationale des Femmes Entrepreneures de la Federation des Entreprises du Congo . Participaient egalement a cette conference de presse les representants des administrations publiques de la Republique Democratique du Congo, les representants des partenaires au developpement en poste en RDC, les medias et les acteurs economiques . Aux termes des allocutions, l'on retiendra qu'avec l'appui de la cooperation francaise, la Republique Democratique du Congo s'est dotee d'une Ecole d'Administration (ENA) toute moderne destinee a former les hauts cadres de l'administration publique congolaise. Pour la formation operationnelle des auditeurs de cette haute ecole, l'Ambassade de France a Kinshasa travaille en collaboration avec l'Ambassade de Belgique a Kinshasa . L'on retiendra egalement qu'a travers son Agence de financement des actions de developpement, l'AFD, la cooperation francaise appuie la mise en œuvre du droit OHADA, non seulement en RDC, mais dans toute l'espace OHADA.\", 'content_type': 'text', 'score': 0.7268285306426902, 'meta': {'posted_at': '', '_split_id': 1}, 'embedding': None, 'id': '112d353c29567e60fabd98a3a9a4f644'}>,\n",
       " <Document: {'content': \"Nous avons le plaisir de vous informer que l'Ambassade de France en Republique Democratique du Congo a tenu, le 3 novembre 2014, une conference de presse au cours de laquelle les actions de la cooperation francaise en faveur de l'appui a l'appropriation du Droit OHADA ont ete presentees au public. Ces actions s'inscrivent dans le cadre des appuis que l'ensemble de la communaute internationale, Banque Mondiale, Union Europeenne, cooperations bilaterales britannique (DFID), belge et autres apportent a l'OHADA et a l'approfondissement de l'Etat de droit economique, de la securite juridique et judicaire, en RDC . Cette conference, largement couverte par les medias, etait co-presidee par Monsieur Philippe LARRIEU, Chef du Service de Cooperation et d'Action Culturelle (SCAC) de l'Ambassade de France et Directeur de l'Institut Francais de Kinshasa et par le Professeur Roger MASAMBA, President de la Commission Nationale OHADA de la Republique Democratique du Congo.\", 'content_type': 'text', 'score': 0.7260812612179223, 'meta': {'posted_at': '', '_split_id': 0}, 'embedding': None, 'id': '1fd4da90fb8070ed86e53bf0480d5ae7'}>,\n",
       " <Document: {'content': 'Burundi / Republique Democratique du Congo / Rwanda', 'content_type': 'text', 'score': 0.7233961181323455, 'meta': {'posted_at': '', '_split_id': 0}, 'embedding': None, 'id': '51a0662b7c2e5a7ec715781f48e0c368'}>,\n",
       " <Document: {'content': 'Des habitants vivant dans cette zone de la Republique Democratique du Congo avaient relaye des images et videos de cet appareil sur la toile.', 'content_type': 'text', 'score': 0.7148635937840184, 'meta': {'posted_at': '', '_split_id': 1}, 'embedding': None, 'id': 'e3fad5b4081172003c43e712ba6e225a'}>,\n",
       " <Document: {'content': 'Sous le leadership du President et la conduite du Premier ministre, le jeune ministre deploie aussi des tresors de diplomatie pour faire entendre la voix de la RDC. Le succes de la visite du Vice-president de la Commission europeenne est aussi a mettre a l’actif du ministre de l’Environnement. Lequel a conduit l’Homme d’Etat europeen aupres de toutes les autorites centrales congolaises, a savoir le President de la republique, le President de l’assemblee nationale, le speaker du Senat et le Premier ministre. Jose NAWEJCOMMUNIQUE OFFICIEL DU MINISTERE DE L’ENVIRONNEMENT ET DU DEVELOPPEMENT DURABLE\\nLa Republique Democratique du Congo va officiellement deposer sa contribution nationale au Bureau de la Convention des Nations Unies sur le changement climatique au plus tard le 15 aout prochain. L’annonce a ete faite par le Chef de l’Etat, Son Excellence Joseph Kabila Kabange lors de l’audience qu’il a accordee ce samedi 18 juillet au Vice-President de la Commission Europeenne, M. Maros Sefcovic conduit par le Ministre de l’Environnement et du Developpement Durable, M. Bienvenu Liyota Ndjoli.', 'content_type': 'text', 'score': 0.712180078669562, 'meta': {'posted_at': '', '_split_id': 2}, 'embedding': None, 'id': '319c1d5a61605ca66f41087892058f77'}>,\n",
       " <Document: {'content': 'Il sied de rappeler par ailleurs que 15 de 26 provinces de la Republique Democratique du Congo sont a ce jour touchees par le coronavirus.', 'content_type': 'text', 'score': 0.7121512320520668, 'meta': {'posted_at': '', '_split_id': 1}, 'embedding': None, 'id': '41cd3636b1ac261e8b295f14af3f9ebf'}>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hard_negative_context(bm25_retriever, question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to build the dense passage retrieval dataset , for each sentence we will find the name entities and mask them and query the database to find hard negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Dense Passage Retrieval Dataset\n",
    "\n",
    "Adding the documents to the retriever store , the next step will be to build the dense passage retrieval dataset.\n",
    "\n",
    "We will consider each paragraph as the answer, and we will generate differents question in the paragraph by masking the name entities which yield to a better score.\n",
    "\n",
    "Once we have a question and the paragraph answer , we will retrieve the negative context with the code we wrote above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER on the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "# this model is good but it is not classifiying roles exactly., we need to improve that. confusing ministre and ministere\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_ner_pipeline = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    " def replace_between(text, begin, end, word_to_replace,  alternative='<MASK>'):\n",
    "    to_replace = text[begin:end]\n",
    "    # assert to_replace.strip() == word_to_replace.strip()\n",
    "    return f\"{text[:begin]} {alternative} {text[end+1:]}\"\n",
    "\n",
    "def filter_entities(entities):\n",
    "    \"\"\"filter the entities and keep only name , org, loc, date and the entity with a score of more than 85%\n",
    "\n",
    "    Args:\n",
    "        entities (_type_): _description_\n",
    "    \"\"\"\n",
    "    return [entity for entity in entities if entity.get(\"entity_group\") in [\"PER\", \"ORG\", \"LOC\", \"DATE\"] and entity.get(\"score\") >= 0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_question_answers_from_sentences(sentence, nlp):\n",
    "    \"\"\"given a sentence build the question and the answers from the sentence.\n",
    "    Args:\n",
    "        sentence (_type_): the sentence we are trying to get the NLP from, \n",
    "        nlp: the nlp pipeline that will do the NER.\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    entities = nlp(sentence)\n",
    "    filtered_entities = filter_entities(entities)\n",
    "    data = {\"context\": sentence, \"entities\": filtered_entities}\n",
    "    yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_document = docs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hard_negative_context(\n",
    "    retriever: BM25Retriever, question: str, answer: str, n_ctxs: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    given the question and the answer query the Elastic search document store and return the hard negative context to the question\n",
    "    \"\"\"\n",
    "\n",
    "    documents = bm25_retriever.retrieve(query=question, top_k=10, filters={\"name_to_not_match\": answer})\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Document: {'content': 'Ne en 1945, Kitenge Yesu est decede le 31 mai dernier a l’age de 76 ans et son enterrement se deroulera dans un cadre strictement prive, Selon plusieurs sources a la presidence de la Republique.', 'content_type': 'text', 'score': None, 'meta': {'name': '510.txt', '_split_id': 2}, 'embedding': None, 'id': '65fba14bdc58dee371d1cd95435bf635'}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_hard_negative_context(\n",
    "    retriever: BM25Retriever, question: str, answer: str, n_ctxs: int = 15\n",
    "):\n",
    "    list_hard_neg_ctxs = []\n",
    "    retrieved_docs = get_hard_negative_context(retriever, question, answer, n_ctxs)\n",
    "    for index, retrieved_doc in enumerate(retrieved_docs):\n",
    "        retrieved_doc_text = retrieved_doc.text\n",
    "        if answer.lower() in retrieved_doc_text.lower():\n",
    "            continue\n",
    "        list_hard_neg_ctxs.append(\n",
    "            {\"title\": f\"document_{index}\", \"text\": retrieved_doc_text}\n",
    "        )\n",
    "    return list_hard_neg_ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "context =  build_question_answers_from_sentences(sample_document.content, transformer_ner_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"Les miliciens de la Cooperative pour le Developpement du Congo (CODECO) ont signe une attaque sanglante dans la nuit du 1er fevrier 2022 dans le site des deplaces de Plaine Savo, a Djugu, en Ituri . Nos sources contactees sur place renseignent que plusieurs civils ont ete lachement abattus par les les CODECO. D’apres Ndalo Bise, president du site attaque, les assaillants ont surgi brusquement la nuit du mardi a partir de 21 heures . « Nous comptons presentement plus de 60 morts dans les abris des deplaces » a-t-il declare a la presse locale. Les miliciens CODECO ont attaque dans la nuit du 01 Fevrier 2022 le site Plaine Savo a Djugu, en Ituri. Les premieres informations font etat d'environ 60 personnes massacrees a l'aide des machettes et autres armes blanches. Cette information est aussi confirmee par les sources administratives de la place qui precisent que pres de 60 personnes ont ete tuees. A en croire, le chef de la chefferie de Bahema N’adhere au-moins 59 personnes ont trouve la mort au cours de cette attaque sanglante . 55 corps sont jusque-la retrouves et 4 autres encore a l’Hopital.\",\n",
       " 'entities': [{'entity_group': 'ORG',\n",
       "   'score': 0.9802546,\n",
       "   'word': 'Cooperative pour le Developpement du Congo (CODECO',\n",
       "   'start': 19,\n",
       "   'end': 70},\n",
       "  {'entity_group': 'DATE',\n",
       "   'score': 0.8536582,\n",
       "   'word': '1er fevrier 2022 dans',\n",
       "   'start': 119,\n",
       "   'end': 141},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.9932758,\n",
       "   'word': 'Plaine Savo',\n",
       "   'start': 165,\n",
       "   'end': 177},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.99488115,\n",
       "   'word': 'Djugu',\n",
       "   'start': 180,\n",
       "   'end': 186},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.9953337,\n",
       "   'word': 'Ituri',\n",
       "   'start': 190,\n",
       "   'end': 196},\n",
       "  {'entity_group': 'ORG',\n",
       "   'score': 0.9817336,\n",
       "   'word': 'CODECO',\n",
       "   'start': 302,\n",
       "   'end': 309},\n",
       "  {'entity_group': 'PER',\n",
       "   'score': 0.9956689,\n",
       "   'word': 'Ndalo Bise',\n",
       "   'start': 318,\n",
       "   'end': 329},\n",
       "  {'entity_group': 'DATE',\n",
       "   'score': 0.97516257,\n",
       "   'word': 'mardi',\n",
       "   'start': 406,\n",
       "   'end': 412},\n",
       "  {'entity_group': 'DATE',\n",
       "   'score': 0.99422705,\n",
       "   'word': '21 heures',\n",
       "   'start': 424,\n",
       "   'end': 434},\n",
       "  {'entity_group': 'ORG',\n",
       "   'score': 0.97944266,\n",
       "   'word': 'CODECO',\n",
       "   'start': 561,\n",
       "   'end': 568},\n",
       "  {'entity_group': 'DATE',\n",
       "   'score': 0.9729509,\n",
       "   'word': '01 Fevrier 2022',\n",
       "   'start': 596,\n",
       "   'end': 612},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.9921832,\n",
       "   'word': 'Plaine Savo',\n",
       "   'start': 620,\n",
       "   'end': 632},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.9946966,\n",
       "   'word': 'Djugu',\n",
       "   'start': 634,\n",
       "   'end': 640},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.99543667,\n",
       "   'word': 'Ituri',\n",
       "   'start': 644,\n",
       "   'end': 650},\n",
       "  {'entity_group': 'LOC',\n",
       "   'score': 0.97708285,\n",
       "   'word': 'l’Hopital',\n",
       "   'start': 1097,\n",
       "   'end': 1107}]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(context)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/philipperemy/Stanford-OpenIE-Python\n",
    "# checkout this to build better stuff.\n",
    "def create_dpr_training_dataset(\n",
    "    docs, retriever: BM25Retriever, num_hard_negative_ctxs: int = 30\n",
    "):\n",
    "    n_non_added_questions = 0\n",
    "    n_questions = 0\n",
    "    for  doc in tqdm(docs):\n",
    "        entities_details = build_question_answers_from_sentences(doc.content, nlp)\n",
    "        for entity_detail in entities_details:\n",
    "            context = doc.content\n",
    "            question = entity_detail.get(\"sentence_with_mask\").replace( \"<MASK>\", \"\")\n",
    "            answer = entity_detail.get(\"word\")\n",
    "            hard_negative_contexts = get_hard_negative_context(\n",
    "                retriever=retriever,\n",
    "                question=question,\n",
    "                answer=answer,\n",
    "                n_ctxs=num_hard_negative_ctxs,\n",
    "            )\n",
    "            positive_context = [ {\"text\": context}]\n",
    "            if not hard_negative_contexts or not positive_context:\n",
    "                print(\n",
    "                    f\"No retrieved candidates for article , with question \"\n",
    "                )\n",
    "                n_non_added_questions += 1\n",
    "                continue\n",
    "            dict_DPR = {\n",
    "                \"question\": question,\n",
    "                \"answers\": answer,\n",
    "                \"positive_ctxs\": positive_context,\n",
    "                \"negative_ctxs\": [],\n",
    "                \"hard_negative_ctxs\": hard_negative_contexts,\n",
    "            }\n",
    "            n_questions += 1\n",
    "            yield dict_DPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dpr_path = DATA_PATH.joinpath(\"raw\", \"french-qa\", \"DPR-news-with-mast.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert qa_dpr_path.parent.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4719"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_results = create_dpr_training_dataset(docs, bm25_retriever, num_hard_negative_ctxs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_retrieves_to_json(dpr_results, path):\n",
    "    with open(path, \"w\") as json_file:\n",
    "        json.dump(list(dpr_results), json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5_/n81dq93n79l30d_c34cfqxpr0000gn/T/ipykernel_18086/2628178797.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_docs' is not defined"
     ]
    }
   ],
   "source": [
    "all_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_pipeline = spacy.load(\"fr_dep_news_trf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_id = np.random.randint(0, len(docs))\n",
    "sample_document = docs[random_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Selon le president du Conseil National de Suivi de l\\'Accord et du Processus Electoral, \"CNSA\", les cachots de l\\'Agence Nationale des Renseignements, \"ANR\" ont ete fermes . Information livree par Joseph Olenghankoy ce mercredi 27 mars 2019 via son compte Twitter . \"Je peux me permettre d’attester que tous les cachots de l\\'Agence Nationale de Renseignements en sigle, ANR, sont desormais fermes\", a indique Joseph Olenghankoy . Pour rappel, le chef de l\\'Etat Felix Antoine Tshisekedi Tshilombo avait promis de fermer les cachots de l\\'ANR et d\\'humaniser ce service de securite de la RD Congo . Le 19 mars dernier, Felix Tshisekedi avait nomme de nouveaux dirigeants a l\\'Agence Nationale de Renseignements . A la tete de ce service de securite depuis 8 ans soit de 2011 a 2019, Kalev Mutond administrateur general a ete remplace par Justin Inzun Kakiat.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_sentence(sentence):\n",
    "    \"\"\"# I am not loosing a lot by using only the sentences which ends as with a dot , question mark or exclamation mark \n",
    "\n",
    "    Args:\n",
    "        sentence (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if sentence.endswith((\".\", \"?\", \"!\")) and 20 <=len(sentence) <= 250:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity:\n",
    "    def __init__(self, name, start, end, group):\n",
    "        self.name = name\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.group = group\n",
    "\n",
    "    @staticmethod\n",
    "    def from_dict(cls, dict):\n",
    "        \"\"\"generate an entity from a dict\n",
    "        Args:\n",
    "\n",
    "        Args:\n",
    "            dict (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "\n",
    "        Yields:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        name = dict.get(\"name\")\n",
    "        start = dict.get(\"start\")\n",
    "        end = dict.get(\"end\")\n",
    "        group = dict.get(\"group\")\n",
    "        return cls(name, start, end, group)\n",
    "    \n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    def generate_question_answer(self, entity_start, entity_end):\n",
    "        return self.text[:entity_start] + \"<MASK>\" + self.text[entity_end:], self.text[entity_start:entity_end]\n",
    "\n",
    "    def generate_question_answers(self):\n",
    "        for entity in self.entities:\n",
    "            yield self.generate_question_answer(entity.start, entity.end)\n",
    "    \n",
    "    def get_search_query(self, start, end):\n",
    "        return self.sentence[:start] + \" \" +self.sentence[end:]\n",
    "    \n",
    "    def get_answer(self, entity_start, entity_end):\n",
    "        return self.text[entity_start:entity_end]\n",
    "    \n",
    "    def get_hard_negative_context(self, retriever: BM25Retriever, n_ctxs: int = 15, entity_start: int = 0, entity_end: int = 0):\n",
    "        question = self.get_search_query(entity_start, entity_end)\n",
    "        answer = self.get_answer(entity_start, entity_end)\n",
    "        list_hard_neg_ctxs = []\n",
    "        retrieved_docs = get_hard_negative_context(retriever, question, answer, n_ctxs)\n",
    "        for index, retrieved_doc in enumerate(retrieved_docs):\n",
    "            retrieved_doc_text = retrieved_doc.text\n",
    "            if answer.lower() in retrieved_doc_text.lower():\n",
    "                continue\n",
    "            list_hard_neg_ctxs.append(\n",
    "                {\"title\": f\"document_{index}\", \"text\": retrieved_doc_text}\n",
    "            )\n",
    "\n",
    "        return list_hard_neg_ctxs\n",
    "    \n",
    "    def build_entities(self, ner_pipeline):\n",
    "        \"\"\"given a sentence generate names entities\n",
    "\n",
    "        Args:\n",
    "            ner_pipeline (_type_): _description_\n",
    "        \"\"\"\n",
    "        entities = ner_pipeline(self.text)\n",
    "        filtered_entities = filter_entities(entities)\n",
    "        self.entities = [Entity.from_dict(Entity, entity) for entity in filtered_entities]\n",
    "\n",
    "class DocumentContext:\n",
    "    def __init__(self, content, spacy_pipeline=spacy_pipeline):\n",
    "        self.context = context\n",
    "        self.spacy_pipeline = spacy_pipeline\n",
    "        self.spacy_doc = spacy_pipeline(content)\n",
    "    \n",
    "    def generate_sentences(self):\n",
    "        \"\"\"sentence is a list of sentence from span from context with different entities\n",
    "\n",
    "        Args:\n",
    "            sentences (_type_): _description_\n",
    "        \"\"\"\n",
    "        for sentence in self.split_document_in_sentence():\n",
    "            sentence_object = Sentence(sentence.text)\n",
    "            self.sentences.append(sentence_object)\n",
    "        del self.sentences_list\n",
    "            \n",
    "\n",
    "    def split_document_in_sentence(self):\n",
    "        \"\"\"take the document and yield valid sentences from the document context\n",
    "\n",
    "        Args:\n",
    "            doc (_type_): _description_\n",
    "        \"\"\"\n",
    "        for sentence in self.spacy_doc.sents:\n",
    "            if is_valid_sentence(sentence.text):\n",
    "                yield sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sentence start from 0 and ends at 36 and the text is Selon le president du Conseil National de Suivi de l'Accord et du Processus Electoral, \"CNSA\", les cachots de l'Agence Nationale des Renseignements, \"ANR\" ont ete fermes .\n",
      "the sentence start from 36 and ends at 51 and the text is Information livree par Joseph Olenghankoy ce mercredi 27 mars 2019 via son compte Twitter .\n",
      "the sentence start from 51 and ends at 83 and the text is \"Je peux me permettre d’attester que tous les cachots de l'Agence Nationale de Renseignements en sigle, ANR, sont desormais fermes\", a indique Joseph Olenghankoy .\n",
      "the sentence start from 84 and ends at 116 and the text is rappel, le chef de l'Etat Felix Antoine Tshisekedi Tshilombo avait promis de fermer les cachots de l'ANR et d'humaniser ce service de securite de la RD Congo .\n",
      "the sentence start from 116 and ends at 135 and the text is Le 19 mars dernier, Felix Tshisekedi avait nomme de nouveaux dirigeants a l'Agence Nationale de Renseignements .\n",
      "the sentence start from 135 and ends at 164 and the text is A la tete de ce service de securite depuis 8 ans soit de 2011 a 2019, Kalev Mutond administrateur general a ete remplace par Justin Inzun Kakiat.\n"
     ]
    }
   ],
   "source": [
    "context_data = build_question_answers_from_document(sample_document, transformer_ner_pipeline, spacy_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_context = Context(context_data[\"context\"], context_data.get(\"queries\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'Selon le president du Conseil National de Suivi de l\\'Accord et du Processus Electoral, \"CNSA\", les cachots de l\\'Agence Nationale des Renseignements, \"ANR\" ont ete fermes . Information livree par Joseph Olenghankoy ce mercredi 27 mars 2019 via son compte Twitter . \"Je peux me permettre d’attester que tous les cachots de l\\'Agence Nationale de Renseignements en sigle, ANR, sont desormais fermes\", a indique Joseph Olenghankoy . Pour rappel, le chef de l\\'Etat Felix Antoine Tshisekedi Tshilombo avait promis de fermer les cachots de l\\'ANR et d\\'humaniser ce service de securite de la RD Congo . Le 19 mars dernier, Felix Tshisekedi avait nomme de nouveaux dirigeants a l\\'Agence Nationale de Renseignements . A la tete de ce service de securite depuis 8 ans soit de 2011 a 2019, Kalev Mutond administrateur general a ete remplace par Justin Inzun Kakiat.',\n",
       " 'queries': [{'sentence': {'start': 0, 'end': 36},\n",
       "   'entities': [{'entity_group': 'ORG',\n",
       "     'score': 0.9619928,\n",
       "     'word': \"Conseil National de Suivi de l'Accord et du Processus Electoral\",\n",
       "     'start': 21,\n",
       "     'end': 85},\n",
       "    {'entity_group': 'ORG',\n",
       "     'score': 0.96487457,\n",
       "     'word': '\"CNSA',\n",
       "     'start': 86,\n",
       "     'end': 92},\n",
       "    {'entity_group': 'ORG',\n",
       "     'score': 0.97529477,\n",
       "     'word': \"l'Agence Nationale des Renseignements\",\n",
       "     'start': 109,\n",
       "     'end': 147},\n",
       "    {'entity_group': 'ORG',\n",
       "     'score': 0.9740132,\n",
       "     'word': '\"ANR\"',\n",
       "     'start': 148,\n",
       "     'end': 154}]},\n",
       "  {'sentence': {'start': 36, 'end': 51},\n",
       "   'entities': [{'entity_group': 'PER',\n",
       "     'score': 0.99629766,\n",
       "     'word': 'Joseph Olenghankoy',\n",
       "     'start': 22,\n",
       "     'end': 41},\n",
       "    {'entity_group': 'DATE',\n",
       "     'score': 0.9602839,\n",
       "     'word': 'ce mercredi 27 mars 2019',\n",
       "     'start': 41,\n",
       "     'end': 66}]},\n",
       "  {'sentence': {'start': 51, 'end': 83},\n",
       "   'entities': [{'entity_group': 'ORG',\n",
       "     'score': 0.9785847,\n",
       "     'word': \"l'Agence Nationale de Renseignements\",\n",
       "     'start': 56,\n",
       "     'end': 93},\n",
       "    {'entity_group': 'ORG',\n",
       "     'score': 0.98036814,\n",
       "     'word': 'ANR',\n",
       "     'start': 103,\n",
       "     'end': 107},\n",
       "    {'entity_group': 'PER',\n",
       "     'score': 0.99622804,\n",
       "     'word': 'Joseph Olenghankoy',\n",
       "     'start': 142,\n",
       "     'end': 161}]},\n",
       "  {'sentence': {'start': 84, 'end': 116},\n",
       "   'entities': [{'entity_group': 'PER',\n",
       "     'score': 0.99616694,\n",
       "     'word': 'Felix Antoine Tshisekedi Tshilombo',\n",
       "     'start': 25,\n",
       "     'end': 60},\n",
       "    {'entity_group': 'ORG',\n",
       "     'score': 0.97487736,\n",
       "     'word': \"l'ANR\",\n",
       "     'start': 98,\n",
       "     'end': 104},\n",
       "    {'entity_group': 'LOC',\n",
       "     'score': 0.99176896,\n",
       "     'word': 'RD Congo',\n",
       "     'start': 148,\n",
       "     'end': 157}]},\n",
       "  {'sentence': {'start': 116, 'end': 135},\n",
       "   'entities': [{'entity_group': 'DATE',\n",
       "     'score': 0.988105,\n",
       "     'word': 'Le 19 mars dernier',\n",
       "     'start': 0,\n",
       "     'end': 18},\n",
       "    {'entity_group': 'PER',\n",
       "     'score': 0.99634415,\n",
       "     'word': 'Felix Tshisekedi',\n",
       "     'start': 19,\n",
       "     'end': 36},\n",
       "    {'entity_group': 'ORG',\n",
       "     'score': 0.97093505,\n",
       "     'word': \"l'Agence Nationale de Renseignements\",\n",
       "     'start': 73,\n",
       "     'end': 110}]},\n",
       "  {'sentence': {'start': 135, 'end': 164},\n",
       "   'entities': [{'entity_group': 'DATE',\n",
       "     'score': 0.9910619,\n",
       "     'word': '8 ans',\n",
       "     'start': 42,\n",
       "     'end': 48},\n",
       "    {'entity_group': 'DATE',\n",
       "     'score': 0.9076403,\n",
       "     'word': '2011 a 2019',\n",
       "     'start': 56,\n",
       "     'end': 68},\n",
       "    {'entity_group': 'PER',\n",
       "     'score': 0.99639416,\n",
       "     'word': 'Kalev Mutond',\n",
       "     'start': 69,\n",
       "     'end': 82},\n",
       "    {'entity_group': 'PER',\n",
       "     'score': 0.9963048,\n",
       "     'word': 'Justin Inzun Kakiat',\n",
       "     'start': 124,\n",
       "     'end': 144}]}]}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_context.generate_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selon le president du Conseil Nation\n",
      "Selon le president du<MASK>  Conseil Nation\n",
      "******************************\n",
      "Selon le president du Conseil Nation<MASK> \n",
      "******************************\n",
      "Selon le president du Conseil Nation<MASK> \n",
      "******************************\n",
      "Selon le president du Conseil Nation<MASK> \n",
      "******************************\n",
      "al de Suivi de \n",
      "al de Suivi de <MASK> \n",
      "******************************\n",
      "al de Suivi de <MASK> \n",
      "******************************\n",
      "l'Accord et du Processus Elector\n",
      "l'Accord et du Processus Elector<MASK> \n",
      "******************************\n",
      "l'Accord et du Processus Elector<MASK> \n",
      "******************************\n",
      "l'Accord et du Processus Elector<MASK> \n",
      "******************************\n",
      "l, \"CNSA\", les cachots de l'Agen\n",
      "l, \"CNSA\", les cachots de<MASK>  l'Agen\n",
      "******************************\n",
      "l, \"CNSA\", les cachots de l'Agen<MASK> \n",
      "******************************\n",
      "l, \"CNSA\", les cachots de l'Agen<MASK> \n",
      "******************************\n",
      "ce Nationale des Re\n",
      "<MASK>e ce Nationale des R\n",
      "******************************\n",
      "ce Nationale des Re<MASK> \n",
      "******************************\n",
      "ce Nationale des Re<MASK> \n",
      "******************************\n",
      "nseignements, \"ANR\" ont ete f\n",
      "nseignements, \"ANR\" ont ete f<MASK> \n",
      "******************************\n",
      "nseignements, \"ANR\" ont ete f<MASK> \n",
      "******************************\n",
      "nseignements, \"ANR\" ont ete f<MASK> \n",
      "******************************\n",
      "nseignements, \"ANR\" ont ete f<MASK> \n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for sentence in sample_context.sentences:\n",
    "    print(sentence.text)\n",
    "    for question, answer in sentence.generate_question_answers():\n",
    "        print(question , answer)\n",
    "        print(\"***\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c2668786ae4e4c4fbfa9e5bd2c1f84381eb94ad61006e099ebff41408861387"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
