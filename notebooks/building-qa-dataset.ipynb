{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Masked Language Model Dataset.\n",
    "\n",
    "In this notebook , we will query our database , get the data and then build the dataset for the Masked language model. \n",
    "\n",
    "To achieve this we will leverage hugging face tranformers for Name entity recogniton, we will train the model on our new article.\n",
    "\n",
    "The data is comming as a list of of document , we will split each document into sentences or paragraphs.\n",
    "\n",
    "For each sentence we will run the NER model and find the entities.\n",
    "\n",
    "For each entity found in a sentence , we will consider the sentence with the masked entity as a question and the entity we have masked as the answer and we will save our dataset in a list for further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DATABASE_URL\n",
    "from src.utils.database_connection_utils import get_database_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, engine = get_database_session(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"select * from article where website_origin not in ('https://www.voalingala.com/', 'https://www.karismatv.cd')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "with engine.connect() as connection:\n",
    "    data = pd.read_sql_query(sql=sql_query, con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = Path.cwd().joinpath(\"data\")\n",
    "assert DATA_PATH.exists(), \"the data path does not exist\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140638, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = DATA_PATH.joinpath(\"corpus\", \"raw\", 'drc-news-raws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, [\"content\", \"posted_at\"]].to_csv(data_file_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file_path, names=[\"content\", \"posted_at\"], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=[\"posted_at\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>posted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Le juge Dieudonné Kamuleta n’a pas remplacé Di...</td>\n",
       "      <td>2022-12-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Le principal opposant au régime de Félix Tshis...</td>\n",
       "      <td>2022-12-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>L’ancien Premier ministre, Augustin Matata Pon...</td>\n",
       "      <td>2022-12-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Le Sénat déclare recevables les propositions d...</td>\n",
       "      <td>2022-12-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Excellence Monsieur le Président et co-fondate...</td>\n",
       "      <td>2022-12-05 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content            posted_at\n",
       "78   Le juge Dieudonné Kamuleta n’a pas remplacé Di...  2022-12-05 00:00:00\n",
       "19   Le principal opposant au régime de Félix Tshis...  2022-12-05 00:00:00\n",
       "77   L’ancien Premier ministre, Augustin Matata Pon...  2022-12-05 00:00:00\n",
       "76   Le Sénat déclare recevables les propositions d...  2022-12-05 00:00:00\n",
       "141  Excellence Monsieur le Président et co-fondate...  2022-12-05 00:00:00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import deaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    input_without_accent = deaccent(input_str)\n",
    "    return input_without_accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_document(document):\n",
    "    \"\"\"given a document split the document into sentences and return a list of those sentence\n",
    "\n",
    "    Args:\n",
    "        document (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    tokenized_document = sent_tokenize(document, language=\"french\")\n",
    "    return tokenized_document\n",
    "\n",
    "def replace_point(document):\n",
    "    \"\"\"replace the point with the wwt.www with space point before tokenizing the document .\n",
    "\n",
    "    Args:\n",
    "        document (_type_): _description_\n",
    "    \"\"\"\n",
    "    result = re.sub(r\"(\\S)\\.(\\S)\", r\"\\1 . \\2\", document)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_document(document):\n",
    "    \"\"\"pre-process the document by removing the accents, replacing the point and tokenizing the document.\n",
    "\n",
    "    Args:\n",
    "        document (_type_): _description_\n",
    "    \"\"\"\n",
    "    document = remove_accents(document)\n",
    "    document = replace_point(document)\n",
    "    document = tokenize_document(document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La guerre fait rage entre les deux Msr.', 'Chaque camp revendique le label du parti.', 'Le Msr pro-pouvoir a indique mercredi qu’il a recu l’agrement du ministere de l’Interieur et menace de traduire en justice ceux qui l’utiliseront abusivement.', 'Le Mouvement social pour le renouveau reste un et indivisible et toujours loyal a son initiateur, le president Joseph Kabila, a indique le depute Francois Rubota.', 'Selon lui, le parti qui evoluait depuis 2005 sous couvert de l’arrete ministeriel du MNR, a finalement eu son propre agrement.', 'Rubota rappelle que le Msr n’a jamais bascule a l’opposition.', 'Il appelle le G7 a revoir sa charte et a ne considerer que six partis et non sept comme l’indique certaines personnes.', 'Entre-temps, le Msr pro-opposition est monte au creneau.', 'Sa direction politique a denonce les strategies de destabilisation du parti par des mains noires.', 'Ils ont appele les militants de leur parti a la resistance pour faire echec a cet arrete ministeriel, peut-on lire dans leur declaration.', 'L’option a ete levee pour saisir la justice afin de mettre fin a la confusion.', 'Mais deja au siege du Msr pro-opposition, on voit flotter les drapeaux du G 7.', 'Signe que Pierre Lumbi appelle a la solidarite d’autres partis membres du G7.', 'Alors la plupart connaissent eux-aussi les memes cas de bicephalisme.']\n"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, data.shape[0])\n",
    "sample_doc = data.content[random_index]\n",
    "print(pre_process_document(sample_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.sub(r\"(\\S)\\.(\\S)\", r\"\\1 . \\2\", sample_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Dynamique pour la Sauvegarde et la Consolidation des Acquis Démocratiques a échangé le week-end dernier avec des jeunes  des confessions religieuses des communes de Mont-Ngafula et Selembao autour du thème : \"Comment consolider et sauvegarder les acquis démocratiques ?\". Ce thème a permis de faire un état de lieu sur le fonctionnement des institutions actuelles en République Démocratique du Congo . Au regard de divergences sur les lois en ce qui concerne les élections constatées dans le chef de certains politiques, le conférencier du jour, le professeur Auguste Mampuya, a invité l'assistance à ne pas se laisser distraire par ces opinions d'intérêts égoïstes . \"Il y en a qui veulent toucher à tel aspect, il y en a qui veulent toucher à un tel autre aspect, tout simplement parce que chacun veut que les lois servent ses propres intérêts\", a déclaré le professeur Auguste Mampuya . Ce dernier a appelé à une vraie unité pour permettre la mise en place des réformes totales et profondes de toute la nation congolaise . Pour leur part, les jeunes des communes précitées, bénéficiaires de ces échanges, ont manifesté leur satisfaction d'y avoir pris part . Il sied de rappeler par ailleurs que depuis plusieurs mois, des démarches sont initiées par des organisations de la société civile et certains acteurs politiques sur  le consensus autour des reformes électorales. C'est le cas par exemple du Groupe de 13 personnalités politiques et sociales signataires de l'appel du 11 juillet pour un consensus sur le processus électoral qui a déposé une proposition de loi modifiant et complétant la loi électorale.\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.util import concat\n",
    "from gensim.corpora.csvcorpus import CsvCorpus\n",
    "from gensim.utils import deaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import csv\n",
    "import itertools\n",
    "from gensim import utils\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded our dataset , the next step is to leverage the HuggingFace transformer to train the model. to find the NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner-with-dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets import token_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc_new_corpus_file_with_masks = DATA_PATH.joinpath(\"interim\", \"drc-news-with-masked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert drc_new_corpus_file_with_masks.parent.exists(), \"the corpus file does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_drc_new_corpus_file = DATA_PATH.joinpath(\"corpus\", \"raw\", \"drc-news-raws.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert input_drc_new_corpus_file.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "drc_news_corpus = DrcNewsCorpus(input_drc_new_corpus_file, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363434it [84:19:09,  3.82it/s]                                  "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "drc_news_corpus.save_question_answer_to_file(drc_new_corpus_file_with_masks, n_sample=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c2668786ae4e4c4fbfa9e5bd2c1f84381eb94ad61006e099ebff41408861387"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
