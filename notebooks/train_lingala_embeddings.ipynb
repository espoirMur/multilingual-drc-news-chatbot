{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Lingala Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook , we will be trying to learn lingal word embeddings using fastext and charcter word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 4 differents datasets collected from different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The JW300 lingala dataset\n",
    "- The lingala news dataset collected from voa lingala webesite and karisma tv\n",
    "- The lingala pdf a corpus of dataset collect from random lingala pdf such the congolese drc constitution and other document from related domains\n",
    "- song lyrics data set a dataset with lyrics of around 20 lingala songs scrapped online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was cleanned using different cleaning procedure which can be found in separate notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this reasearch is to try to apply those embedding technics to try to learn lingala vector and see if the word similarity on those models make senses for native speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.cwd().parent.joinpath(\"data\", \"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_files = data_path.glob(\"*.ln\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/news.lingala.ln'),\n",
       " PosixPath('/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/from_pdf_cleanned.ln'),\n",
       " PosixPath('/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/JW.ln'),\n",
       " PosixPath('/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/songs_lingala.ln')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpus_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can do better by igonring the jw corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_pattern = \".*([a-zA-Z]+)\\.ln\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.api import StreamBackedCorpusView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.util import concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.textcorpus import TextDirectoryCorpus\n",
    "from gensim.utils import deaccent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCorpusReader(TextDirectoryCorpus):\n",
    "    def raw(self):\n",
    "        \"\"\"\n",
    "        :return: the given file(s) as a single string.\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        raw_texts = []\n",
    "        for file in self.iter_filepaths():\n",
    "            print(file, 10 * \"88=\")\n",
    "            with open(file, 'r') as file_content:\n",
    "                raw_texts.append(file_content.read())\n",
    "                \n",
    "        return concat(raw_texts)\n",
    "    \n",
    "    \n",
    "    def getstream(self):\n",
    "        \"\"\"Generate documents from the underlying plain text collection (of one or more files).\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        str\n",
    "            One document (if lines_are_documents - True), otherwise - each file is one document.\n",
    "\n",
    "        \"\"\"\n",
    "        num_texts = 0\n",
    "        for path in self.iter_filepaths():\n",
    "            with open(path, 'rt') as f:\n",
    "                if self.lines_are_documents:\n",
    "                    for line in f:\n",
    "                        line = line.replace(\"ɛ\", 'e') # this character is not handle by deaccent\n",
    "                        yield deaccent(line.strip())\n",
    "                        num_texts += 1\n",
    "                else:\n",
    "                    yield f.read().strip()\n",
    "                    num_texts += 1\n",
    "\n",
    "        self.length = num_texts\n",
    "            \n",
    "    def save_text(self, path):\n",
    "        \"\"\"\n",
    "        save the corpus text to the given path\n",
    "        \"\"\"\n",
    "        raw_text = self.raw()\n",
    "        with open(path.joinpath(\"ln.txt\"), 'w') as output:\n",
    "            output.write(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_corpus = CustomCorpusReader(data_path, pattern=language_pattern, lines_are_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of documents in the corpus {{lingala_corpus.dictionary.num_docs}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the vocabulary size is {{len(lingala_corpus.dictionary.token2id)}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'botɛmɛli'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaccent(\"botɛmɛli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yehova', 'alingi', 'ete', 'bato', 'mabota', 'nyonso', 'bayeba', 'mikano']\n",
      "['yango', 'tokomaki', 'liste', 'nkombo', 'moto', 'nyonso', 'lisanga', 'oyo', 'ndako', 'ebebisamaki']\n",
      "['ouganda', 'tokokuta', 'likambo', 'oyo', 'emonanaka', 'bikolo', 'mingi', 'okoki', 'kolongwa', 'esika', 'molunge', 'mpe', 'nsima', 'kotambola', 'kaka', 'mwa', 'moke', 'okomi', 'esika', 'malili', 'makasi']\n",
      "['longola', 'kobondela', 'mpo', 'kosenga', 'elimo', 'yango', 'tosengeli', 'komileisa', 'mpenza', 'liloba', 'nzambe', 'oyo', 'ekomamaki', 'litambwisi', 'elimo', 'santu']\n",
      "['ntango', 'nayebaki', 'yango', 'nazalaki', 'lisusu', 'kobanga', 'nzambe', 'ndenge', 'mabe']\n"
     ]
    }
   ],
   "source": [
    "for text in lingala_corpus.sample_texts(5):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this now , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = Path.cwd().parent.parent.joinpath('lacuna_pos_ner', 'language_corpus', 'ln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/es.py/Projects/Personal/lacuna_pos_ner/language_corpus/ln')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/news.lingala.ln 88=88=88=88=88=88=88=88=88=88=\n",
      "/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/from_pdf_cleanned.ln 88=88=88=88=88=88=88=88=88=88=\n",
      "/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/JW.ln 88=88=88=88=88=88=88=88=88=88=\n",
      "/Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/data/processed/songs_lingala.ln 88=88=88=88=88=88=88=88=88=88=\n"
     ]
    }
   ],
   "source": [
    "lingala_corpus.save_text(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615294"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingala_corpus.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Enable logging at the `INFO` level and set a custom format--the\n",
    "# default log format is pretty wordy. \n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(message)s', # Display just time and message.\n",
    "    datefmt='%H:%M:%S', # Display time, but not the date.\n",
    "    level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Building Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our corpus is now time to build our embedding . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "cpu_cores = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45:11 : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastText(sentences=None, # Don't provide the sentences yet, otherwise\n",
    "                    # it will kick off the training automatically.\n",
    "                          size=100,    # Number of features in word vector\n",
    "                          window=10,   # Context window size (in each direction)\n",
    "                 #   Default is 5\n",
    "                          min_count=2, # Words must appear this many times to be in vocab.\n",
    "                 #   Default is 5\n",
    "                          workers=cpu_cores,  # Training thread count\n",
    "                          sg=1,        # 0: CBOW, 1: Skip-gram. \n",
    "                 #   Default is 0, CBOW\n",
    "                          hs=1,        # 0: Negative Sampling, 1: Hierarchical Softmax\n",
    "                 #   Default is 0, NS\n",
    "\n",
    "                          negative=5,  # Nmber of negative samples (default is 5)\n",
    "    \n",
    "                          sample=1e-3, # The coefficient for the subsampling of frequent words\n",
    "                 # equation.\n",
    "                          word_ngrams=1, # Turn on n-grams.\n",
    "                          min_n=5,       # Min n-gram size of 3 characters (default is 3).\n",
    "                          max_n=10,       # Max n-gram size of 6 characters (default is 6).\n",
    "    \n",
    "                         bucket=2000000, # Initial number of buckets for the n-gram hash table.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(lingala_corpus.get_texts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:25 : collecting all words and their counts\n",
      "20:46:25 : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "20:46:26 : PROGRESS: at sentence #20000, processed 376766 words, keeping 24962 word types\n",
      "20:46:26 : PROGRESS: at sentence #40000, processed 633878 words, keeping 31992 word types\n",
      "20:46:26 : PROGRESS: at sentence #60000, processed 896471 words, keeping 36212 word types\n",
      "20:46:26 : PROGRESS: at sentence #80000, processed 1121251 words, keeping 38934 word types\n",
      "20:46:26 : PROGRESS: at sentence #100000, processed 1344700 words, keeping 41143 word types\n",
      "20:46:26 : PROGRESS: at sentence #120000, processed 1604725 words, keeping 44701 word types\n",
      "20:46:26 : PROGRESS: at sentence #140000, processed 1871174 words, keeping 47583 word types\n",
      "20:46:26 : PROGRESS: at sentence #160000, processed 2136724 words, keeping 49722 word types\n",
      "20:46:26 : PROGRESS: at sentence #180000, processed 2398166 words, keeping 51801 word types\n",
      "20:46:26 : PROGRESS: at sentence #200000, processed 2664485 words, keeping 53459 word types\n",
      "20:46:26 : PROGRESS: at sentence #220000, processed 2921135 words, keeping 54771 word types\n",
      "20:46:26 : PROGRESS: at sentence #240000, processed 3166260 words, keeping 56073 word types\n",
      "20:46:26 : PROGRESS: at sentence #260000, processed 3423730 words, keeping 57072 word types\n",
      "20:46:26 : PROGRESS: at sentence #280000, processed 3680211 words, keeping 57967 word types\n",
      "20:46:26 : PROGRESS: at sentence #300000, processed 3944784 words, keeping 58969 word types\n",
      "20:46:26 : PROGRESS: at sentence #320000, processed 4208491 words, keeping 59829 word types\n",
      "20:46:27 : PROGRESS: at sentence #340000, processed 4453659 words, keeping 60635 word types\n",
      "20:46:27 : PROGRESS: at sentence #360000, processed 4696487 words, keeping 61478 word types\n",
      "20:46:27 : PROGRESS: at sentence #380000, processed 4932171 words, keeping 62303 word types\n",
      "20:46:27 : PROGRESS: at sentence #400000, processed 5165475 words, keeping 62953 word types\n",
      "20:46:27 : PROGRESS: at sentence #420000, processed 5398587 words, keeping 63570 word types\n",
      "20:46:27 : PROGRESS: at sentence #440000, processed 5612278 words, keeping 64251 word types\n",
      "20:46:27 : PROGRESS: at sentence #460000, processed 5826677 words, keeping 64894 word types\n",
      "20:46:27 : PROGRESS: at sentence #480000, processed 6046057 words, keeping 65470 word types\n",
      "20:46:27 : PROGRESS: at sentence #500000, processed 6267598 words, keeping 66083 word types\n",
      "20:46:27 : PROGRESS: at sentence #520000, processed 6490734 words, keeping 66736 word types\n",
      "20:46:27 : PROGRESS: at sentence #540000, processed 6720581 words, keeping 67280 word types\n",
      "20:46:27 : PROGRESS: at sentence #560000, processed 6956375 words, keeping 67779 word types\n",
      "20:46:27 : PROGRESS: at sentence #580000, processed 7185274 words, keeping 68269 word types\n",
      "20:46:27 : PROGRESS: at sentence #600000, processed 7406221 words, keeping 68625 word types\n",
      "20:46:27 : collected 70404 word types from a corpus of 7585746 raw words and 615294 sentences\n",
      "20:46:27 : Loading a fresh vocabulary\n",
      "20:46:28 : effective_min_count=2 retains 42417 unique words (60% of original 70404, drops 27987)\n",
      "20:46:28 : effective_min_count=2 leaves 7557759 word corpus (99% of original 7585746, drops 27987)\n",
      "20:46:28 : deleting the raw counts dictionary of 70404 items\n",
      "20:46:28 : sample=0.001 downsamples 54 most-common words\n",
      "20:46:28 : downsampling leaves estimated 5833479 word corpus (77.2% of prior 7557759)\n",
      "20:46:28 : constructing a huffman tree from 42417 words\n",
      "20:46:29 : built huffman tree with maximum node depth 22\n",
      "20:46:30 : estimated required memory for 42417 words, 349991 buckets and 100 dimensions: 229456644 bytes\n",
      "20:46:30 : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 2.25 s, total: 22.5 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fasttext_model.build_vocab(\n",
    "    sentences, \n",
    "    progress_per=20000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615294"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingala_corpus.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:44 : training model with 8 workers on 42417 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:46:45 : EPOCH 1 - PROGRESS: at 0.64% examples, 67683 words/s, in_qsize 15, out_qsize 0\n",
      "20:46:55 : EPOCH 1 - PROGRESS: at 21.52% examples, 123991 words/s, in_qsize 16, out_qsize 0\n",
      "20:47:05 : EPOCH 1 - PROGRESS: at 42.05% examples, 125138 words/s, in_qsize 16, out_qsize 0\n",
      "20:47:16 : EPOCH 1 - PROGRESS: at 61.99% examples, 122352 words/s, in_qsize 15, out_qsize 0\n",
      "20:47:26 : EPOCH 1 - PROGRESS: at 85.29% examples, 122077 words/s, in_qsize 14, out_qsize 1\n",
      "20:47:32 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:47:32 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:47:32 : EPOCH - 1 : training on 7585746 raw words (5833371 effective words) took 47.7s, 122279 effective words/s\n",
      "20:47:33 : EPOCH 2 - PROGRESS: at 0.64% examples, 52324 words/s, in_qsize 15, out_qsize 0\n",
      "20:47:44 : EPOCH 2 - PROGRESS: at 14.32% examples, 81912 words/s, in_qsize 16, out_qsize 0\n",
      "20:47:54 : EPOCH 2 - PROGRESS: at 31.30% examples, 92644 words/s, in_qsize 15, out_qsize 0\n",
      "20:48:04 : EPOCH 2 - PROGRESS: at 50.82% examples, 100495 words/s, in_qsize 15, out_qsize 0\n",
      "20:48:14 : EPOCH 2 - PROGRESS: at 74.58% examples, 107343 words/s, in_qsize 15, out_qsize 0\n",
      "20:48:24 : EPOCH 2 - PROGRESS: at 98.78% examples, 111117 words/s, in_qsize 10, out_qsize 0\n",
      "20:48:24 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:48:24 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:48:24 : EPOCH - 2 : training on 7585746 raw words (5834260 effective words) took 52.4s, 111421 effective words/s\n",
      "20:48:26 : EPOCH 3 - PROGRESS: at 0.64% examples, 59132 words/s, in_qsize 16, out_qsize 1\n",
      "20:48:36 : EPOCH 3 - PROGRESS: at 17.58% examples, 100793 words/s, in_qsize 16, out_qsize 0\n",
      "20:48:46 : EPOCH 3 - PROGRESS: at 36.62% examples, 109686 words/s, in_qsize 15, out_qsize 0\n",
      "20:48:56 : EPOCH 3 - PROGRESS: at 58.03% examples, 115206 words/s, in_qsize 15, out_qsize 1\n",
      "20:49:06 : EPOCH 3 - PROGRESS: at 81.79% examples, 117540 words/s, in_qsize 15, out_qsize 0\n",
      "20:49:12 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:49:12 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:49:12 : EPOCH - 3 : training on 7585746 raw words (5833575 effective words) took 47.9s, 121707 effective words/s\n",
      "20:49:14 : EPOCH 4 - PROGRESS: at 0.64% examples, 61756 words/s, in_qsize 15, out_qsize 0\n",
      "20:49:24 : EPOCH 4 - PROGRESS: at 20.79% examples, 119273 words/s, in_qsize 14, out_qsize 0\n",
      "20:49:34 : EPOCH 4 - PROGRESS: at 42.53% examples, 126243 words/s, in_qsize 16, out_qsize 0\n",
      "20:49:44 : EPOCH 4 - PROGRESS: at 66.26% examples, 129693 words/s, in_qsize 15, out_qsize 0\n",
      "20:49:54 : EPOCH 4 - PROGRESS: at 93.52% examples, 132558 words/s, in_qsize 15, out_qsize 0\n",
      "20:49:56 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:49:56 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:49:56 : EPOCH - 4 : training on 7585746 raw words (5832286 effective words) took 44.1s, 132128 effective words/s\n",
      "20:49:58 : EPOCH 5 - PROGRESS: at 0.63% examples, 56717 words/s, in_qsize 15, out_qsize 0\n",
      "20:50:08 : EPOCH 5 - PROGRESS: at 22.25% examples, 125989 words/s, in_qsize 15, out_qsize 0\n",
      "20:50:18 : EPOCH 5 - PROGRESS: at 44.61% examples, 131143 words/s, in_qsize 16, out_qsize 1\n",
      "20:50:28 : EPOCH 5 - PROGRESS: at 68.52% examples, 132644 words/s, in_qsize 15, out_qsize 0\n",
      "20:50:38 : EPOCH 5 - PROGRESS: at 96.15% examples, 135392 words/s, in_qsize 15, out_qsize 0\n",
      "20:50:39 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:50:39 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:50:39 : EPOCH - 5 : training on 7585746 raw words (5834480 effective words) took 42.9s, 136003 effective words/s\n",
      "20:50:41 : EPOCH 6 - PROGRESS: at 0.63% examples, 62156 words/s, in_qsize 15, out_qsize 0\n",
      "20:50:51 : EPOCH 6 - PROGRESS: at 22.47% examples, 128949 words/s, in_qsize 15, out_qsize 0\n",
      "20:51:01 : EPOCH 6 - PROGRESS: at 44.61% examples, 131755 words/s, in_qsize 15, out_qsize 0\n",
      "20:51:11 : EPOCH 6 - PROGRESS: at 70.03% examples, 135788 words/s, in_qsize 15, out_qsize 0\n",
      "20:51:21 : EPOCH 6 - PROGRESS: at 98.78% examples, 139282 words/s, in_qsize 10, out_qsize 0\n",
      "20:51:21 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:51:21 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:51:21 : EPOCH - 6 : training on 7585746 raw words (5833839 effective words) took 41.8s, 139583 effective words/s\n",
      "20:51:23 : EPOCH 7 - PROGRESS: at 0.64% examples, 61746 words/s, in_qsize 16, out_qsize 0\n",
      "20:51:33 : EPOCH 7 - PROGRESS: at 22.36% examples, 128143 words/s, in_qsize 16, out_qsize 0\n",
      "20:51:43 : EPOCH 7 - PROGRESS: at 43.27% examples, 128348 words/s, in_qsize 16, out_qsize 1\n",
      "20:51:53 : EPOCH 7 - PROGRESS: at 67.90% examples, 132230 words/s, in_qsize 15, out_qsize 0\n",
      "20:52:03 : EPOCH 7 - PROGRESS: at 96.59% examples, 136131 words/s, in_qsize 16, out_qsize 0\n",
      "20:52:04 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:52:04 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:52:04 : EPOCH - 7 : training on 7585746 raw words (5832820 effective words) took 42.7s, 136593 effective words/s\n",
      "20:52:05 : EPOCH 8 - PROGRESS: at 0.63% examples, 61439 words/s, in_qsize 16, out_qsize 0\n",
      "20:52:16 : EPOCH 8 - PROGRESS: at 22.47% examples, 126132 words/s, in_qsize 16, out_qsize 1\n",
      "20:52:26 : EPOCH 8 - PROGRESS: at 44.98% examples, 131504 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:52:36 : EPOCH 8 - PROGRESS: at 70.33% examples, 135343 words/s, in_qsize 14, out_qsize 1\n",
      "20:52:46 : EPOCH 8 - PROGRESS: at 98.78% examples, 138535 words/s, in_qsize 10, out_qsize 0\n",
      "20:52:46 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:52:46 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:52:46 : EPOCH - 8 : training on 7585746 raw words (5833891 effective words) took 42.1s, 138619 effective words/s\n",
      "20:52:47 : EPOCH 9 - PROGRESS: at 0.64% examples, 62166 words/s, in_qsize 16, out_qsize 0\n",
      "20:52:57 : EPOCH 9 - PROGRESS: at 22.36% examples, 127871 words/s, in_qsize 16, out_qsize 0\n",
      "20:53:07 : EPOCH 9 - PROGRESS: at 42.77% examples, 126817 words/s, in_qsize 15, out_qsize 0\n",
      "20:53:18 : EPOCH 9 - PROGRESS: at 65.45% examples, 127498 words/s, in_qsize 16, out_qsize 0\n",
      "20:53:28 : EPOCH 9 - PROGRESS: at 92.25% examples, 130285 words/s, in_qsize 15, out_qsize 0\n",
      "20:53:30 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:53:30 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:53:30 : EPOCH - 9 : training on 7585746 raw words (5833058 effective words) took 44.3s, 131728 effective words/s\n",
      "20:53:32 : EPOCH 10 - PROGRESS: at 0.63% examples, 60245 words/s, in_qsize 14, out_qsize 1\n",
      "20:53:42 : EPOCH 10 - PROGRESS: at 22.47% examples, 127603 words/s, in_qsize 12, out_qsize 3\n",
      "20:53:52 : EPOCH 10 - PROGRESS: at 45.69% examples, 133620 words/s, in_qsize 14, out_qsize 1\n",
      "20:54:02 : EPOCH 10 - PROGRESS: at 72.16% examples, 138126 words/s, in_qsize 16, out_qsize 0\n",
      "20:54:12 : EPOCH 10 - PROGRESS: at 98.64% examples, 138222 words/s, in_qsize 11, out_qsize 0\n",
      "20:54:12 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:54:12 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:54:12 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:54:12 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:54:12 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:54:12 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:54:13 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:54:13 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:54:13 : EPOCH - 10 : training on 7585746 raw words (5833588 effective words) took 42.1s, 138446 effective words/s\n",
      "20:54:14 : EPOCH 11 - PROGRESS: at 0.63% examples, 61957 words/s, in_qsize 16, out_qsize 2\n",
      "20:54:24 : EPOCH 11 - PROGRESS: at 22.96% examples, 131102 words/s, in_qsize 15, out_qsize 0\n",
      "20:54:34 : EPOCH 11 - PROGRESS: at 45.58% examples, 134139 words/s, in_qsize 15, out_qsize 0\n",
      "20:54:44 : EPOCH 11 - PROGRESS: at 71.26% examples, 137394 words/s, in_qsize 15, out_qsize 0\n",
      "20:54:54 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:54:54 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:54:54 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:54:54 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:54:54 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:54:54 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:54:54 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:54:54 : EPOCH 11 - PROGRESS: at 100.00% examples, 140585 words/s, in_qsize 0, out_qsize 1\n",
      "20:54:54 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:54:54 : EPOCH - 11 : training on 7585746 raw words (5833287 effective words) took 41.5s, 140580 effective words/s\n",
      "20:54:55 : EPOCH 12 - PROGRESS: at 0.64% examples, 62264 words/s, in_qsize 15, out_qsize 0\n",
      "20:55:05 : EPOCH 12 - PROGRESS: at 22.59% examples, 129328 words/s, in_qsize 16, out_qsize 1\n",
      "20:55:15 : EPOCH 12 - PROGRESS: at 45.70% examples, 134814 words/s, in_qsize 15, out_qsize 0\n",
      "20:55:26 : EPOCH 12 - PROGRESS: at 70.96% examples, 137004 words/s, in_qsize 16, out_qsize 0\n",
      "20:55:36 : EPOCH 12 - PROGRESS: at 98.93% examples, 139113 words/s, in_qsize 9, out_qsize 0\n",
      "20:55:36 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:55:36 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:55:36 : EPOCH - 12 : training on 7585746 raw words (5832543 effective words) took 41.9s, 139304 effective words/s\n",
      "20:55:37 : EPOCH 13 - PROGRESS: at 0.64% examples, 62582 words/s, in_qsize 15, out_qsize 0\n",
      "20:55:47 : EPOCH 13 - PROGRESS: at 21.88% examples, 125613 words/s, in_qsize 15, out_qsize 0\n",
      "20:55:57 : EPOCH 13 - PROGRESS: at 43.27% examples, 128433 words/s, in_qsize 15, out_qsize 0\n",
      "20:56:07 : EPOCH 13 - PROGRESS: at 67.63% examples, 131928 words/s, in_qsize 15, out_qsize 0\n",
      "20:56:18 : EPOCH 13 - PROGRESS: at 96.59% examples, 136101 words/s, in_qsize 16, out_qsize 0\n",
      "20:56:18 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:56:18 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:56:18 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:56:18 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:56:18 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:56:18 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:56:19 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:56:19 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:56:19 : EPOCH - 13 : training on 7585746 raw words (5833065 effective words) took 42.7s, 136668 effective words/s\n",
      "20:56:20 : EPOCH 14 - PROGRESS: at 0.63% examples, 62504 words/s, in_qsize 14, out_qsize 1\n",
      "20:56:30 : EPOCH 14 - PROGRESS: at 22.71% examples, 130508 words/s, in_qsize 15, out_qsize 0\n",
      "20:56:40 : EPOCH 14 - PROGRESS: at 45.70% examples, 134961 words/s, in_qsize 15, out_qsize 0\n",
      "20:56:50 : EPOCH 14 - PROGRESS: at 71.26% examples, 137672 words/s, in_qsize 16, out_qsize 0\n",
      "20:57:00 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:57:00 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:57:00 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:57:00 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:57:00 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:57:00 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:57:00 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:57:00 : EPOCH 14 - PROGRESS: at 100.00% examples, 140916 words/s, in_qsize 0, out_qsize 1\n",
      "20:57:00 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:57:00 : EPOCH - 14 : training on 7585746 raw words (5833828 effective words) took 41.4s, 140908 effective words/s\n",
      "20:57:01 : EPOCH 15 - PROGRESS: at 0.64% examples, 60465 words/s, in_qsize 16, out_qsize 1\n",
      "20:57:11 : EPOCH 15 - PROGRESS: at 23.22% examples, 132493 words/s, in_qsize 15, out_qsize 0\n",
      "20:57:22 : EPOCH 15 - PROGRESS: at 44.74% examples, 131233 words/s, in_qsize 15, out_qsize 0\n",
      "20:57:32 : EPOCH 15 - PROGRESS: at 69.74% examples, 134655 words/s, in_qsize 15, out_qsize 0\n",
      "20:57:42 : EPOCH 15 - PROGRESS: at 98.93% examples, 138669 words/s, in_qsize 9, out_qsize 0\n",
      "20:57:42 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:57:42 : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:57:42 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:57:42 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:57:42 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:57:42 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:57:42 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:57:42 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:57:42 : EPOCH - 15 : training on 7585746 raw words (5831917 effective words) took 42.0s, 138765 effective words/s\n",
      "20:57:43 : EPOCH 16 - PROGRESS: at 0.63% examples, 62112 words/s, in_qsize 14, out_qsize 1\n",
      "20:57:54 : EPOCH 16 - PROGRESS: at 22.96% examples, 131206 words/s, in_qsize 16, out_qsize 0\n",
      "20:58:04 : EPOCH 16 - PROGRESS: at 45.70% examples, 135025 words/s, in_qsize 15, out_qsize 0\n",
      "20:58:14 : EPOCH 16 - PROGRESS: at 71.40% examples, 137984 words/s, in_qsize 16, out_qsize 1\n",
      "20:58:23 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:58:23 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:58:23 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:58:23 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:58:23 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:58:23 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:58:23 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:58:24 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:58:24 : EPOCH - 16 : training on 7585746 raw words (5835055 effective words) took 41.3s, 141257 effective words/s\n",
      "20:58:25 : EPOCH 17 - PROGRESS: at 0.64% examples, 61027 words/s, in_qsize 15, out_qsize 0\n",
      "20:58:35 : EPOCH 17 - PROGRESS: at 22.84% examples, 130709 words/s, in_qsize 16, out_qsize 0\n",
      "20:58:45 : EPOCH 17 - PROGRESS: at 45.35% examples, 134046 words/s, in_qsize 15, out_qsize 0\n",
      "20:58:55 : EPOCH 17 - PROGRESS: at 70.04% examples, 135886 words/s, in_qsize 15, out_qsize 0\n",
      "20:59:05 : EPOCH 17 - PROGRESS: at 97.34% examples, 137518 words/s, in_qsize 15, out_qsize 0\n",
      "20:59:06 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:59:06 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:59:06 : EPOCH - 17 : training on 7585746 raw words (5833658 effective words) took 42.3s, 137949 effective words/s\n",
      "20:59:07 : EPOCH 18 - PROGRESS: at 0.64% examples, 61381 words/s, in_qsize 15, out_qsize 0\n",
      "20:59:17 : EPOCH 18 - PROGRESS: at 20.54% examples, 117684 words/s, in_qsize 15, out_qsize 0\n",
      "20:59:27 : EPOCH 18 - PROGRESS: at 38.78% examples, 115270 words/s, in_qsize 15, out_qsize 0\n",
      "20:59:37 : EPOCH 18 - PROGRESS: at 60.54% examples, 119290 words/s, in_qsize 16, out_qsize 0\n",
      "20:59:47 : EPOCH 18 - PROGRESS: at 88.21% examples, 125521 words/s, in_qsize 15, out_qsize 0\n",
      "20:59:51 : worker thread finished; awaiting finish of 7 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 6 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 5 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 4 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 3 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 2 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 1 more threads\n",
      "20:59:51 : worker thread finished; awaiting finish of 0 more threads\n",
      "20:59:51 : EPOCH - 18 : training on 7585746 raw words (5832515 effective words) took 45.5s, 128201 effective words/s\n",
      "20:59:53 : EPOCH 19 - PROGRESS: at 0.64% examples, 61568 words/s, in_qsize 16, out_qsize 0\n",
      "21:00:03 : EPOCH 19 - PROGRESS: at 23.34% examples, 133709 words/s, in_qsize 15, out_qsize 0\n",
      "21:00:13 : EPOCH 19 - PROGRESS: at 46.56% examples, 137662 words/s, in_qsize 16, out_qsize 0\n",
      "21:00:23 : EPOCH 19 - PROGRESS: at 72.91% examples, 140668 words/s, in_qsize 16, out_qsize 1\n",
      "21:00:32 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:00:32 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:00:32 : EPOCH - 19 : training on 7585746 raw words (5834029 effective words) took 40.6s, 143800 effective words/s\n",
      "21:00:33 : EPOCH 20 - PROGRESS: at 0.63% examples, 64849 words/s, in_qsize 15, out_qsize 0\n",
      "21:00:43 : EPOCH 20 - PROGRESS: at 22.84% examples, 131606 words/s, in_qsize 16, out_qsize 0\n",
      "21:00:53 : EPOCH 20 - PROGRESS: at 45.81% examples, 135948 words/s, in_qsize 16, out_qsize 1\n",
      "21:01:03 : EPOCH 20 - PROGRESS: at 70.96% examples, 137453 words/s, in_qsize 15, out_qsize 0\n",
      "21:01:13 : EPOCH 20 - PROGRESS: at 96.01% examples, 135936 words/s, in_qsize 16, out_qsize 0\n",
      "21:01:15 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:01:15 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:01:15 : EPOCH - 20 : training on 7585746 raw words (5832816 effective words) took 42.8s, 136399 effective words/s\n",
      "21:01:16 : EPOCH 21 - PROGRESS: at 0.63% examples, 59262 words/s, in_qsize 15, out_qsize 3\n",
      "21:01:26 : EPOCH 21 - PROGRESS: at 20.91% examples, 118956 words/s, in_qsize 15, out_qsize 0\n",
      "21:01:36 : EPOCH 21 - PROGRESS: at 42.77% examples, 126455 words/s, in_qsize 15, out_qsize 0\n",
      "21:01:46 : EPOCH 21 - PROGRESS: at 67.63% examples, 131670 words/s, in_qsize 15, out_qsize 0\n",
      "21:01:56 : EPOCH 21 - PROGRESS: at 95.69% examples, 135243 words/s, in_qsize 15, out_qsize 2\n",
      "21:01:57 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:01:57 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:01:57 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:01:57 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:01:57 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:01:58 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:01:58 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:01:58 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:01:58 : EPOCH - 21 : training on 7585746 raw words (5832782 effective words) took 42.9s, 136039 effective words/s\n",
      "21:01:59 : EPOCH 22 - PROGRESS: at 0.64% examples, 58606 words/s, in_qsize 15, out_qsize 0\n",
      "21:02:09 : EPOCH 22 - PROGRESS: at 21.88% examples, 123454 words/s, in_qsize 16, out_qsize 2\n",
      "21:02:19 : EPOCH 22 - PROGRESS: at 43.14% examples, 126980 words/s, in_qsize 15, out_qsize 0\n",
      "21:02:29 : EPOCH 22 - PROGRESS: at 68.53% examples, 132094 words/s, in_qsize 15, out_qsize 0\n",
      "21:02:39 : EPOCH 22 - PROGRESS: at 95.39% examples, 134082 words/s, in_qsize 15, out_qsize 0\n",
      "21:02:41 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:02:41 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:02:41 : EPOCH - 22 : training on 7585746 raw words (5831603 effective words) took 43.2s, 135003 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:02:42 : EPOCH 23 - PROGRESS: at 0.64% examples, 62379 words/s, in_qsize 16, out_qsize 0\n",
      "21:02:52 : EPOCH 23 - PROGRESS: at 22.96% examples, 131677 words/s, in_qsize 15, out_qsize 0\n",
      "21:03:02 : EPOCH 23 - PROGRESS: at 45.93% examples, 135926 words/s, in_qsize 15, out_qsize 0\n",
      "21:03:12 : EPOCH 23 - PROGRESS: at 72.31% examples, 139674 words/s, in_qsize 15, out_qsize 0\n",
      "21:03:22 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:03:22 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:03:22 : EPOCH - 23 : training on 7585746 raw words (5834247 effective words) took 40.9s, 142752 effective words/s\n",
      "21:03:23 : EPOCH 24 - PROGRESS: at 0.64% examples, 62602 words/s, in_qsize 13, out_qsize 2\n",
      "21:03:33 : EPOCH 24 - PROGRESS: at 23.34% examples, 133576 words/s, in_qsize 15, out_qsize 0\n",
      "21:03:43 : EPOCH 24 - PROGRESS: at 46.56% examples, 136741 words/s, in_qsize 15, out_qsize 0\n",
      "21:03:53 : EPOCH 24 - PROGRESS: at 73.42% examples, 140732 words/s, in_qsize 15, out_qsize 0\n",
      "21:04:02 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:04:02 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:04:02 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:04:02 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:04:02 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:04:02 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:04:03 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:04:03 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:04:03 : EPOCH - 24 : training on 7585746 raw words (5833626 effective words) took 40.7s, 143437 effective words/s\n",
      "21:04:04 : EPOCH 25 - PROGRESS: at 0.64% examples, 63504 words/s, in_qsize 15, out_qsize 0\n",
      "21:04:14 : EPOCH 25 - PROGRESS: at 23.08% examples, 132798 words/s, in_qsize 15, out_qsize 0\n",
      "21:04:24 : EPOCH 25 - PROGRESS: at 46.06% examples, 136344 words/s, in_qsize 15, out_qsize 0\n",
      "21:04:34 : EPOCH 25 - PROGRESS: at 72.62% examples, 140262 words/s, in_qsize 15, out_qsize 0\n",
      "21:04:43 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:04:43 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:04:43 : EPOCH - 25 : training on 7585746 raw words (5833063 effective words) took 40.7s, 143365 effective words/s\n",
      "21:04:45 : EPOCH 26 - PROGRESS: at 0.63% examples, 64862 words/s, in_qsize 15, out_qsize 0\n",
      "21:04:55 : EPOCH 26 - PROGRESS: at 22.84% examples, 131348 words/s, in_qsize 15, out_qsize 0\n",
      "21:05:05 : EPOCH 26 - PROGRESS: at 46.06% examples, 135904 words/s, in_qsize 15, out_qsize 0\n",
      "21:05:15 : EPOCH 26 - PROGRESS: at 72.96% examples, 140437 words/s, in_qsize 15, out_qsize 0\n",
      "21:05:24 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:05:24 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:05:24 : EPOCH - 26 : training on 7585746 raw words (5831859 effective words) took 40.7s, 143387 effective words/s\n",
      "21:05:25 : EPOCH 27 - PROGRESS: at 0.63% examples, 63588 words/s, in_qsize 16, out_qsize 0\n",
      "21:05:35 : EPOCH 27 - PROGRESS: at 23.10% examples, 132645 words/s, in_qsize 15, out_qsize 0\n",
      "21:05:45 : EPOCH 27 - PROGRESS: at 46.18% examples, 136820 words/s, in_qsize 16, out_qsize 0\n",
      "21:05:55 : EPOCH 27 - PROGRESS: at 72.62% examples, 140030 words/s, in_qsize 15, out_qsize 2\n",
      "21:06:05 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:06:05 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:06:05 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:06:05 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:06:05 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:06:05 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:06:05 : EPOCH 27 - PROGRESS: at 99.91% examples, 140574 words/s, in_qsize 1, out_qsize 1\n",
      "21:06:05 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:06:06 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:06:06 : EPOCH - 27 : training on 7585746 raw words (5834330 effective words) took 41.5s, 140538 effective words/s\n",
      "21:06:07 : EPOCH 28 - PROGRESS: at 0.64% examples, 61323 words/s, in_qsize 14, out_qsize 1\n",
      "21:06:17 : EPOCH 28 - PROGRESS: at 21.76% examples, 124647 words/s, in_qsize 15, out_qsize 0\n",
      "21:06:27 : EPOCH 28 - PROGRESS: at 44.61% examples, 131686 words/s, in_qsize 15, out_qsize 0\n",
      "21:06:37 : EPOCH 28 - PROGRESS: at 70.50% examples, 136415 words/s, in_qsize 14, out_qsize 1\n",
      "21:06:47 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:06:47 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:06:47 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:06:47 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:06:47 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:06:47 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:06:47 : EPOCH 28 - PROGRESS: at 99.91% examples, 140676 words/s, in_qsize 1, out_qsize 1\n",
      "21:06:47 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:06:47 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:06:47 : EPOCH - 28 : training on 7585746 raw words (5833484 effective words) took 41.5s, 140674 effective words/s\n",
      "21:06:48 : EPOCH 29 - PROGRESS: at 0.64% examples, 63154 words/s, in_qsize 16, out_qsize 1\n",
      "21:06:58 : EPOCH 29 - PROGRESS: at 23.22% examples, 132628 words/s, in_qsize 15, out_qsize 0\n",
      "21:07:08 : EPOCH 29 - PROGRESS: at 46.18% examples, 136425 words/s, in_qsize 16, out_qsize 0\n",
      "21:07:18 : EPOCH 29 - PROGRESS: at 72.16% examples, 139355 words/s, in_qsize 15, out_qsize 0\n",
      "21:07:28 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:07:28 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:07:28 : EPOCH - 29 : training on 7585746 raw words (5832803 effective words) took 41.0s, 142436 effective words/s\n",
      "21:07:29 : EPOCH 30 - PROGRESS: at 0.63% examples, 63841 words/s, in_qsize 13, out_qsize 2\n",
      "21:07:39 : EPOCH 30 - PROGRESS: at 22.96% examples, 132258 words/s, in_qsize 15, out_qsize 0\n",
      "21:07:49 : EPOCH 30 - PROGRESS: at 45.81% examples, 135870 words/s, in_qsize 15, out_qsize 0\n",
      "21:08:00 : EPOCH 30 - PROGRESS: at 72.16% examples, 138867 words/s, in_qsize 15, out_qsize 0\n",
      "21:08:09 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:08:09 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:08:09 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:08:09 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:08:09 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:08:09 : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:08:09 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:08:09 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:08:09 : EPOCH - 30 : training on 7585746 raw words (5833337 effective words) took 41.0s, 142421 effective words/s\n",
      "21:08:10 : EPOCH 31 - PROGRESS: at 0.63% examples, 64347 words/s, in_qsize 16, out_qsize 0\n",
      "21:08:20 : EPOCH 31 - PROGRESS: at 22.36% examples, 128760 words/s, in_qsize 15, out_qsize 0\n",
      "21:08:30 : EPOCH 31 - PROGRESS: at 42.89% examples, 127673 words/s, in_qsize 15, out_qsize 0\n",
      "21:08:40 : EPOCH 31 - PROGRESS: at 68.67% examples, 134020 words/s, in_qsize 15, out_qsize 0\n",
      "21:08:50 : EPOCH 31 - PROGRESS: at 97.77% examples, 138146 words/s, in_qsize 14, out_qsize 1\n",
      "21:08:51 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:08:51 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:08:51 : EPOCH - 31 : training on 7585746 raw words (5833031 effective words) took 42.1s, 138529 effective words/s\n",
      "21:08:53 : EPOCH 32 - PROGRESS: at 0.64% examples, 53736 words/s, in_qsize 15, out_qsize 0\n",
      "21:09:10 : EPOCH 32 - PROGRESS: at 9.66% examples, 58702 words/s, in_qsize 15, out_qsize 0\n",
      "21:09:20 : EPOCH 32 - PROGRESS: at 27.45% examples, 79389 words/s, in_qsize 16, out_qsize 0\n",
      "21:09:30 : EPOCH 32 - PROGRESS: at 49.61% examples, 96765 words/s, in_qsize 15, out_qsize 0\n",
      "21:09:40 : EPOCH 32 - PROGRESS: at 75.17% examples, 106775 words/s, in_qsize 15, out_qsize 0\n",
      "21:09:49 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:09:49 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:09:49 : EPOCH - 32 : training on 7585746 raw words (5834457 effective words) took 51.4s, 113445 effective words/s\n",
      "21:09:51 : EPOCH 33 - PROGRESS: at 0.64% examples, 58175 words/s, in_qsize 15, out_qsize 0\n",
      "21:18:32 : EPOCH 33 - PROGRESS: at 18.58% examples, 103764 words/s, in_qsize 15, out_qsize 0\n",
      "21:18:42 : EPOCH 33 - PROGRESS: at 40.66% examples, 119134 words/s, in_qsize 15, out_qsize 0\n",
      "21:18:52 : EPOCH 33 - PROGRESS: at 63.48% examples, 123422 words/s, in_qsize 15, out_qsize 0\n",
      "21:19:02 : EPOCH 33 - PROGRESS: at 89.62% examples, 126209 words/s, in_qsize 16, out_qsize 0\n",
      "21:19:06 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:19:06 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:19:06 : EPOCH - 33 : training on 7585746 raw words (5833602 effective words) took 45.5s, 128257 effective words/s\n",
      "21:19:08 : EPOCH 34 - PROGRESS: at 0.64% examples, 58209 words/s, in_qsize 15, out_qsize 0\n",
      "21:19:18 : EPOCH 34 - PROGRESS: at 22.36% examples, 126887 words/s, in_qsize 16, out_qsize 0\n",
      "21:19:28 : EPOCH 34 - PROGRESS: at 43.82% examples, 129145 words/s, in_qsize 15, out_qsize 0\n",
      "21:19:38 : EPOCH 34 - PROGRESS: at 69.01% examples, 133832 words/s, in_qsize 15, out_qsize 0\n",
      "21:19:48 : EPOCH 34 - PROGRESS: at 93.70% examples, 132369 words/s, in_qsize 15, out_qsize 0\n",
      "21:19:50 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:19:50 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:19:50 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:19:50 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:19:50 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:19:50 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:19:51 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:19:51 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:19:51 : EPOCH - 34 : training on 7585746 raw words (5833899 effective words) took 44.1s, 132313 effective words/s\n",
      "21:19:52 : EPOCH 35 - PROGRESS: at 0.64% examples, 60075 words/s, in_qsize 14, out_qsize 1\n",
      "21:20:02 : EPOCH 35 - PROGRESS: at 20.66% examples, 118067 words/s, in_qsize 14, out_qsize 1\n",
      "21:20:12 : EPOCH 35 - PROGRESS: at 43.54% examples, 128639 words/s, in_qsize 15, out_qsize 0\n",
      "21:20:22 : EPOCH 35 - PROGRESS: at 69.30% examples, 134431 words/s, in_qsize 15, out_qsize 0\n",
      "21:20:32 : EPOCH 35 - PROGRESS: at 93.38% examples, 132324 words/s, in_qsize 16, out_qsize 0\n",
      "21:20:34 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:20:34 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:20:34 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:20:34 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:20:34 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:20:34 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:20:35 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:20:35 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:20:35 : EPOCH - 35 : training on 7585746 raw words (5832303 effective words) took 44.0s, 132529 effective words/s\n",
      "21:20:36 : EPOCH 36 - PROGRESS: at 0.64% examples, 55927 words/s, in_qsize 15, out_qsize 0\n",
      "21:20:46 : EPOCH 36 - PROGRESS: at 20.19% examples, 114487 words/s, in_qsize 15, out_qsize 0\n",
      "21:20:56 : EPOCH 36 - PROGRESS: at 39.02% examples, 115694 words/s, in_qsize 15, out_qsize 0\n",
      "21:21:06 : EPOCH 36 - PROGRESS: at 59.58% examples, 117561 words/s, in_qsize 15, out_qsize 0\n",
      "21:21:16 : EPOCH 36 - PROGRESS: at 87.54% examples, 124501 words/s, in_qsize 15, out_qsize 0\n",
      "21:21:20 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:21:21 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:21:21 : EPOCH - 36 : training on 7585746 raw words (5833870 effective words) took 46.1s, 126583 effective words/s\n",
      "21:21:22 : EPOCH 37 - PROGRESS: at 0.63% examples, 63350 words/s, in_qsize 16, out_qsize 0\n",
      "21:21:32 : EPOCH 37 - PROGRESS: at 22.84% examples, 131394 words/s, in_qsize 15, out_qsize 0\n",
      "21:21:42 : EPOCH 37 - PROGRESS: at 45.70% examples, 135403 words/s, in_qsize 15, out_qsize 0\n",
      "21:21:52 : EPOCH 37 - PROGRESS: at 72.16% examples, 139114 words/s, in_qsize 15, out_qsize 0\n",
      "21:22:01 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:22:01 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:22:01 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:22:02 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:22:02 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:22:02 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:22:02 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:22:02 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:22:02 : EPOCH - 37 : training on 7585746 raw words (5832307 effective words) took 41.0s, 142340 effective words/s\n",
      "21:22:03 : EPOCH 38 - PROGRESS: at 0.64% examples, 62901 words/s, in_qsize 16, out_qsize 0\n",
      "21:22:13 : EPOCH 38 - PROGRESS: at 22.96% examples, 131348 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:22:23 : EPOCH 38 - PROGRESS: at 46.06% examples, 136085 words/s, in_qsize 15, out_qsize 0\n",
      "21:22:33 : EPOCH 38 - PROGRESS: at 72.62% examples, 140002 words/s, in_qsize 15, out_qsize 0\n",
      "21:22:42 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:22:42 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:22:42 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:22:42 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:22:42 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:22:42 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:22:42 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:22:43 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:22:43 : EPOCH - 38 : training on 7585746 raw words (5833382 effective words) took 40.8s, 143136 effective words/s\n",
      "21:22:44 : EPOCH 39 - PROGRESS: at 0.63% examples, 64520 words/s, in_qsize 14, out_qsize 1\n",
      "21:22:54 : EPOCH 39 - PROGRESS: at 23.10% examples, 132990 words/s, in_qsize 15, out_qsize 0\n",
      "21:23:04 : EPOCH 39 - PROGRESS: at 46.05% examples, 136159 words/s, in_qsize 14, out_qsize 1\n",
      "21:23:14 : EPOCH 39 - PROGRESS: at 72.61% examples, 139974 words/s, in_qsize 16, out_qsize 1\n",
      "21:23:23 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:23:23 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:23:23 : EPOCH - 39 : training on 7585746 raw words (5833051 effective words) took 40.8s, 142832 effective words/s\n",
      "21:23:25 : EPOCH 40 - PROGRESS: at 0.64% examples, 65220 words/s, in_qsize 15, out_qsize 0\n",
      "21:23:35 : EPOCH 40 - PROGRESS: at 22.84% examples, 131446 words/s, in_qsize 15, out_qsize 0\n",
      "21:23:45 : EPOCH 40 - PROGRESS: at 46.06% examples, 136534 words/s, in_qsize 15, out_qsize 0\n",
      "21:23:55 : EPOCH 40 - PROGRESS: at 72.62% examples, 140399 words/s, in_qsize 15, out_qsize 0\n",
      "21:24:04 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:24:04 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:24:04 : EPOCH - 40 : training on 7585746 raw words (5832982 effective words) took 40.7s, 143265 effective words/s\n",
      "21:24:05 : EPOCH 41 - PROGRESS: at 0.63% examples, 62954 words/s, in_qsize 15, out_qsize 0\n",
      "21:24:15 : EPOCH 41 - PROGRESS: at 22.71% examples, 130297 words/s, in_qsize 15, out_qsize 0\n",
      "21:24:26 : EPOCH 41 - PROGRESS: at 45.81% examples, 135077 words/s, in_qsize 15, out_qsize 0\n",
      "21:24:36 : EPOCH 41 - PROGRESS: at 72.47% examples, 139417 words/s, in_qsize 15, out_qsize 0\n",
      "21:24:45 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:24:45 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:24:45 : EPOCH - 41 : training on 7585746 raw words (5833534 effective words) took 41.0s, 142125 effective words/s\n",
      "21:24:47 : EPOCH 42 - PROGRESS: at 0.63% examples, 64026 words/s, in_qsize 15, out_qsize 0\n",
      "21:24:57 : EPOCH 42 - PROGRESS: at 22.47% examples, 128423 words/s, in_qsize 14, out_qsize 1\n",
      "21:25:07 : EPOCH 42 - PROGRESS: at 44.61% examples, 131833 words/s, in_qsize 16, out_qsize 0\n",
      "21:25:17 : EPOCH 42 - PROGRESS: at 70.96% examples, 137137 words/s, in_qsize 16, out_qsize 0\n",
      "21:25:34 : EPOCH 42 - PROGRESS: at 85.74% examples, 122240 words/s, in_qsize 15, out_qsize 0\n",
      "21:25:42 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:25:42 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:25:42 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:25:43 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:25:43 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:25:43 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:25:43 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:25:43 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:25:43 : EPOCH - 42 : training on 7585746 raw words (5833244 effective words) took 50.1s, 116319 effective words/s\n",
      "21:25:44 : EPOCH 43 - PROGRESS: at 0.63% examples, 61546 words/s, in_qsize 15, out_qsize 0\n",
      "21:25:54 : EPOCH 43 - PROGRESS: at 22.36% examples, 128183 words/s, in_qsize 15, out_qsize 0\n",
      "21:26:04 : EPOCH 43 - PROGRESS: at 43.82% examples, 129970 words/s, in_qsize 16, out_qsize 1\n",
      "21:26:14 : EPOCH 43 - PROGRESS: at 65.72% examples, 128445 words/s, in_qsize 15, out_qsize 0\n",
      "21:46:28 : EPOCH 43 - PROGRESS: at 88.08% examples, 125445 words/s, in_qsize 15, out_qsize 0\n",
      "21:46:31 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:46:31 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:46:31 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:46:31 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:46:31 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:46:31 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:46:32 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:46:32 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:46:32 : EPOCH - 43 : training on 7585746 raw words (5833659 effective words) took 45.3s, 128755 effective words/s\n",
      "21:46:33 : EPOCH 44 - PROGRESS: at 0.64% examples, 63824 words/s, in_qsize 13, out_qsize 2\n",
      "21:46:43 : EPOCH 44 - PROGRESS: at 21.88% examples, 125936 words/s, in_qsize 16, out_qsize 0\n",
      "21:46:53 : EPOCH 44 - PROGRESS: at 42.29% examples, 125833 words/s, in_qsize 15, out_qsize 0\n",
      "21:47:03 : EPOCH 44 - PROGRESS: at 63.76% examples, 125388 words/s, in_qsize 15, out_qsize 0\n",
      "21:47:13 : EPOCH 44 - PROGRESS: at 84.27% examples, 120356 words/s, in_qsize 16, out_qsize 1\n",
      "21:47:20 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:47:20 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:47:20 : EPOCH - 44 : training on 7585746 raw words (5833800 effective words) took 48.2s, 120978 effective words/s\n",
      "21:47:21 : EPOCH 45 - PROGRESS: at 0.63% examples, 56717 words/s, in_qsize 15, out_qsize 0\n",
      "21:47:31 : EPOCH 45 - PROGRESS: at 18.83% examples, 107143 words/s, in_qsize 15, out_qsize 0\n",
      "21:47:41 : EPOCH 45 - PROGRESS: at 34.82% examples, 104106 words/s, in_qsize 14, out_qsize 1\n",
      "21:47:52 : EPOCH 45 - PROGRESS: at 51.97% examples, 103476 words/s, in_qsize 14, out_qsize 1\n",
      "21:48:02 : EPOCH 45 - PROGRESS: at 73.26% examples, 106306 words/s, in_qsize 15, out_qsize 0\n",
      "21:48:12 : EPOCH 45 - PROGRESS: at 96.59% examples, 109524 words/s, in_qsize 15, out_qsize 0\n",
      "21:48:13 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:48:13 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:48:13 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:48:13 : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:48:13 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:48:13 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:48:13 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:48:13 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:48:13 : EPOCH - 45 : training on 7585746 raw words (5833858 effective words) took 52.9s, 110241 effective words/s\n",
      "21:48:15 : EPOCH 46 - PROGRESS: at 0.63% examples, 46783 words/s, in_qsize 16, out_qsize 1\n",
      "21:48:25 : EPOCH 46 - PROGRESS: at 18.08% examples, 100504 words/s, in_qsize 15, out_qsize 0\n",
      "21:48:35 : EPOCH 46 - PROGRESS: at 35.32% examples, 104177 words/s, in_qsize 15, out_qsize 0\n",
      "21:48:45 : EPOCH 46 - PROGRESS: at 57.36% examples, 112212 words/s, in_qsize 13, out_qsize 2\n",
      "21:48:55 : EPOCH 46 - PROGRESS: at 82.52% examples, 116995 words/s, in_qsize 15, out_qsize 0\n",
      "21:49:01 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:49:01 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:49:01 : EPOCH - 46 : training on 7585746 raw words (5832509 effective words) took 48.4s, 120424 effective words/s\n",
      "21:49:03 : EPOCH 47 - PROGRESS: at 0.64% examples, 46317 words/s, in_qsize 13, out_qsize 2\n",
      "21:49:13 : EPOCH 47 - PROGRESS: at 19.57% examples, 107930 words/s, in_qsize 14, out_qsize 1\n",
      "21:49:23 : EPOCH 47 - PROGRESS: at 32.67% examples, 96143 words/s, in_qsize 15, out_qsize 1\n",
      "21:49:33 : EPOCH 47 - PROGRESS: at 47.52% examples, 93720 words/s, in_qsize 15, out_qsize 0\n",
      "21:49:43 : EPOCH 47 - PROGRESS: at 67.36% examples, 97969 words/s, in_qsize 15, out_qsize 0\n",
      "21:49:54 : EPOCH 47 - PROGRESS: at 92.54% examples, 104296 words/s, in_qsize 15, out_qsize 0\n",
      "21:49:56 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:49:56 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:49:56 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:49:56 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:49:56 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:49:57 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:49:57 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:49:57 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:49:57 : EPOCH - 47 : training on 7585746 raw words (5832836 effective words) took 55.3s, 105461 effective words/s\n",
      "21:49:58 : EPOCH 48 - PROGRESS: at 0.64% examples, 53991 words/s, in_qsize 15, out_qsize 0\n",
      "21:50:08 : EPOCH 48 - PROGRESS: at 18.71% examples, 105557 words/s, in_qsize 16, out_qsize 0\n",
      "21:50:18 : EPOCH 48 - PROGRESS: at 35.97% examples, 107053 words/s, in_qsize 16, out_qsize 0\n",
      "21:50:28 : EPOCH 48 - PROGRESS: at 48.54% examples, 96349 words/s, in_qsize 15, out_qsize 0\n",
      "21:50:38 : EPOCH 48 - PROGRESS: at 63.21% examples, 93358 words/s, in_qsize 16, out_qsize 0\n",
      "21:50:49 : EPOCH 48 - PROGRESS: at 88.65% examples, 100882 words/s, in_qsize 15, out_qsize 0\n",
      "21:50:53 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:50:53 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:50:53 : EPOCH - 48 : training on 7585746 raw words (5834121 effective words) took 56.1s, 103925 effective words/s\n",
      "21:50:54 : EPOCH 49 - PROGRESS: at 0.63% examples, 56496 words/s, in_qsize 14, out_qsize 1\n",
      "21:51:04 : EPOCH 49 - PROGRESS: at 17.58% examples, 99108 words/s, in_qsize 15, out_qsize 0\n",
      "21:51:14 : EPOCH 49 - PROGRESS: at 39.28% examples, 115830 words/s, in_qsize 15, out_qsize 0\n",
      "21:51:25 : EPOCH 49 - PROGRESS: at 62.52% examples, 122089 words/s, in_qsize 16, out_qsize 0\n",
      "21:51:35 : EPOCH 49 - PROGRESS: at 89.19% examples, 126295 words/s, in_qsize 15, out_qsize 0\n",
      "21:51:38 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:51:38 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:51:38 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:51:38 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:51:38 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:51:38 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:51:39 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:51:39 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:51:39 : EPOCH - 49 : training on 7585746 raw words (5834661 effective words) took 45.6s, 127857 effective words/s\n",
      "21:51:40 : EPOCH 50 - PROGRESS: at 0.64% examples, 60870 words/s, in_qsize 16, out_qsize 1\n",
      "21:51:50 : EPOCH 50 - PROGRESS: at 22.25% examples, 126560 words/s, in_qsize 15, out_qsize 0\n",
      "21:52:00 : EPOCH 50 - PROGRESS: at 43.82% examples, 128989 words/s, in_qsize 15, out_qsize 0\n",
      "21:52:10 : EPOCH 50 - PROGRESS: at 66.68% examples, 129704 words/s, in_qsize 15, out_qsize 0\n",
      "21:52:20 : EPOCH 50 - PROGRESS: at 94.53% examples, 133039 words/s, in_qsize 15, out_qsize 0\n",
      "21:52:22 : worker thread finished; awaiting finish of 7 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 6 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 5 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 4 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 3 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 2 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 1 more threads\n",
      "21:52:22 : worker thread finished; awaiting finish of 0 more threads\n",
      "21:52:22 : EPOCH - 50 : training on 7585746 raw words (5833884 effective words) took 43.8s, 133133 effective words/s\n",
      "21:52:22 : training on a 379287300 raw words (291668005 effective words) took 2208.9s, 132042 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training the model...')\n",
    "fasttext_model.train(\n",
    "    sentences,\n",
    "    total_examples=len(sentences),\n",
    "    epochs=50,        # How many training passes to take.\n",
    "    report_delay=10.0 # Report progress every 10 seconds.\n",
    ")\n",
    "\n",
    "print('  Done.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to comeback to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yoka', 0.6531233787536621),\n",
       " ('oboyi', 0.639123797416687),\n",
       " ('olobi', 0.632038950920105),\n",
       " ('yebisa', 0.6240906715393066),\n",
       " ('kenda', 0.6033507585525513),\n",
       " ('lela', 0.6004784107208252),\n",
       " ('kende', 0.5960424542427063),\n",
       " ('nga', 0.5856990814208984),\n",
       " ('yaka', 0.5788900852203369),\n",
       " ('oko', 0.5777283906936646),\n",
       " ('olobaki', 0.5737762451171875),\n",
       " ('nayo', 0.5720775127410889),\n",
       " ('oyebi', 0.5718715190887451),\n",
       " ('oyebisa', 0.5716909766197205),\n",
       " ('olalisi', 0.571544349193573),\n",
       " ('fanda', 0.5672937631607056),\n",
       " ('yeba', 0.5636211037635803),\n",
       " ('nako', 0.5590487122535706),\n",
       " ('olobaka', 0.5553001761436462),\n",
       " ('opesi', 0.5536763072013855)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('loba', topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the model train we need now to do the evaluation to see if the training was well done , we will evaluate the model on word similarity and see if we can benchmark our model for more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd().parent.joinpath('models', 'lingala_embeddings_fasttext', 'embedding_50_all_lingala_corpus.bin').__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:33:12 : saving FastText object under /Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/models/embedding_50_all_lingala_corpus.bin, separately None\n",
      "13:33:12 : storing np array 'vectors_ngrams' to /Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/models/embedding_50_all_lingala_corpus.bin.wv.vectors_ngrams.npy\n",
      "13:33:16 : not storing attribute vectors_ngrams_norm\n",
      "13:33:16 : not storing attribute vectors_norm\n",
      "13:33:16 : not storing attribute vectors_vocab_norm\n",
      "13:33:16 : not storing attribute buckets_word\n",
      "13:33:16 : storing np array 'vectors_ngrams_lockf' to /Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/models/embedding_50_all_lingala_corpus.bin.trainables.vectors_ngrams_lockf.npy\n",
      "13:33:21 : saved /Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/models/embedding_50_all_lingala_corpus.bin\n"
     ]
    }
   ],
   "source": [
    "fasttext_model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the models Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now evaluate the models results using the [wordsim-353](http://alfonseca.org/eng/research/wordsim353.html) test set to see how the model perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('babalani', 0.734166145324707),\n",
       " ('kobalana', 0.6804149150848389),\n",
       " ('mabala', 0.6746077537536621),\n",
       " ('kobala', 0.6322838068008423),\n",
       " ('abali', 0.6285107135772705),\n",
       " ('bafianse', 0.6059749126434326),\n",
       " ('abala', 0.5939195156097412),\n",
       " ('kokabwana', 0.58404541015625),\n",
       " ('akobala', 0.5825542211532593),\n",
       " ('mobali', 0.5815414190292358),\n",
       " ('babalana', 0.57380211353302),\n",
       " ('molongani', 0.5736296772956848),\n",
       " ('mobalani', 0.5734422206878662),\n",
       " ('bonzemba', 0.5729975700378418),\n",
       " ('bamoniselana', 0.561253011226654),\n",
       " ('balongani', 0.5600625276565552),\n",
       " ('aniversere', 0.5555722713470459),\n",
       " ('ndai', 0.5520299673080444),\n",
       " ('komoniselana', 0.5491830110549927),\n",
       " ('balingani', 0.545312762260437)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('libala', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1714239"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.similarity('mokuse', 'munene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'mayele' in correct_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mapeka', 0.6647143959999084),\n",
       " ('abwakeli', 0.5789598822593689),\n",
       " ('lipeka', 0.5772056579589844),\n",
       " ('natutaki', 0.5740435123443604),\n",
       " ('elongi', 0.5642611384391785),\n",
       " ('sakosi', 0.5619938969612122),\n",
       " ('kopale', 0.5568258762359619),\n",
       " ('libenga', 0.5465318560600281),\n",
       " ('niati', 0.5460203289985657),\n",
       " ('koningisa', 0.5440565347671509),\n",
       " ('lokolo', 0.5393606424331665),\n",
       " ('libaya', 0.538963794708252),\n",
       " ('simisi', 0.535095751285553),\n",
       " ('navimbaki', 0.5325905084609985),\n",
       " ('loketo', 0.531934380531311),\n",
       " ('asimbi', 0.530055582523346),\n",
       " ('lisasi', 0.5297955274581909),\n",
       " ('elamba', 0.5292395353317261),\n",
       " ('lizita', 0.5230260491371155),\n",
       " ('avimbivimbi', 0.5224087238311768),\n",
       " ('aningisi', 0.5212208032608032),\n",
       " ('lobɔkɔ', 0.5183290243148804),\n",
       " ('molangi', 0.518175482749939),\n",
       " ('fukama', 0.5165168046951294),\n",
       " ('epasukaka', 0.515727162361145)]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('', topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_word = ['mbongo', 'kelasi', 'libala', 'wenge',\n",
    "                'pesa', 'kosala', 'kulutu', 'kende', \n",
    "                'mawa', 'ndeko', 'makila',\n",
    "                'senga', 'mpasi', 'mawa', 'ekolo', 'jammal', 'kamerhe', \n",
    "                'ozuwa', 'lokuta', 'etat', 'depute', 'zala', 'mawa', 'feti', \n",
    "                'lata', 'facture', 'nganda', 'mikanda', 'limbisa', 'sila', \n",
    "                'bilamba', 'koma', 'loba', 'bana', 'mwinda', 'ndako', \n",
    "                'mosala', 'zando', 'zoba', 'beta', 'maladie', 'mpongo', 'nzita',\n",
    "                'rwanda', 'uganda', 'kabila', 'kelela', 'futa', 'eloko', 'mungwa', \n",
    "                'nzembo', 'bilamba', 'somba', 'futa', 'mawa', 'yaka', 'bilei', 'sabuni',\n",
    "                'mabe', 'zonga', 'masumu', 'kanda', 'mosapi']\n",
    "incorect_words = ['esengo', 'nzela', 'tika', 'salongo', 'mokuse', \n",
    "                  'tiya', 'mbulatari', 'solola', 'mona', 'munene', \n",
    "                  'mokuse', 'tanga', 'lelo', 'lobi', 'molayi', 'zonga', 'sengi', 'seka']\n",
    "not_sure = ['liputa', 'zamba', 'lokuta', 'oyebi', 'losambo', \n",
    "            'ezui', 'ndenge', 'yuma', 'mpondu', 'ofele',\n",
    "            'ndoki', 'nzoto', 'mayele']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(correct_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to go from here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the words seems to make sense we can try to use them in a machine translation or using them in visualization to see if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vec2graph import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using Character word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train using character word embedding , we will be using the charcter base word embedding model from [this source](https://github.com/Leonard-Xu/CWE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can leverage the code build in C to train the model.\n",
    "\n",
    "The first step to train the model is to update our corpus by adding `<s> and  </s>` tags to each line of the corpus.\n",
    "The second step is to train the modele using the following command : \n",
    "    \n",
    "`./cwe -corpus -output-word cwelp/cbow20/twi_bible.txt -output-char cwelp/char_c20/twi_bible_char.txt -size 100 -window 10 -sample 1e-4 -negative 5 -hs 0 -iter 50 -min-count 1 -cwe-type 4 cbow 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I updating the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomCorpusReader at 0x11ec80f98>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingala_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = Path.cwd().parent.joinpath('data', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    " def save_text(self, path):\n",
    "    \"\"\"\n",
    "    save the corpus text to the given path\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path.joinpath(\"lingala_corpus_with_delimeters.ln\"), 'a') as output:\n",
    "        for line in self.get_texts():\n",
    "            line = ' '.join(line)\n",
    "            line = f\"<s> {line} </s> \\n\"\n",
    "            output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text(lingala_corpus, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object TextCorpus.get_texts at 0x13aaa71a8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lingala_corpus.get_texts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is done with the following script,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shouldn't we use the chinese character to train?\n",
    "\n",
    "`../CWE/src/cwe -train ./data/processed/lingala_corpus_with_delimeters.ln   -output-word ./models/lingala_embeddings_cwe/vectors.txt -output-char ./models/lingala_embeddings_cwe/chars.txt -size 100 -window 10 -sample 1e-4 -negative 5 -hs 0 -iter 50 -min-count 1 -cwe-type 4 cbow 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have train the embedding , let see how to load them and check how they perform on the embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have training the data for the embedding , the code is save as txt files with each word and it's vector representation, \n",
    "let now load the code and try to check our similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cwe_data_path = Path.cwd().parent.joinpath('models', \"lingala_embeddings_cwe\", \"vectors.txt\")\n",
    "model_cwe_output_data_path = Path.cwd().parent.joinpath('models', \"lingala_embeddings_cwe\", \"embedding_50_all_lingala_cwe_corpus.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "model_cwe_df = pd.read_csv(model_cwe_data_path, header=None, index_col=0, sep='\t', skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cwe_df = model_cwe_df.drop(101, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwe_embedding_dict = model_cwe_df.T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import to_utf8\n",
    "from smart_open import open as smart_open\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word2vec_format(fname, vocab, vector_size, binary=True):\n",
    "    \"\"\"Store the input-hidden weight matrix in the same format used by the original\n",
    "    C word2vec-tool, for compatibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The file path used to save the vectors in.\n",
    "    vocab : dict\n",
    "        The vocabulary of words.\n",
    "    vector_size : int\n",
    "        The number of dimensions of word vectors.\n",
    "    binary : bool, optional\n",
    "        If True, the data wil be saved in binary word2vec format, else it will be saved in plain text.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    total_vec = len(vocab)\n",
    "    with smart_open(fname, 'wb') as fout:\n",
    "        print(total_vec, vector_size)\n",
    "        fout.write(to_utf8(\"%s %s\\n\" % (total_vec, vector_size)))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, row in tqdm(vocab.items()):\n",
    "            if binary:\n",
    "                row  = np.array(row)\n",
    "                word = str(word)\n",
    "                row = row.astype(np.float32)\n",
    "                fout.write(to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(to_utf8(\"%s %s\\n\" % (word, ' '.join(repr(val) for val in row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 20872/70404 [00:00<00:00, 104366.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70404 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70404/70404 [00:00<00:00, 107783.87it/s]\n"
     ]
    }
   ],
   "source": [
    "save_word2vec_format(binary=True, fname=model_cwe_output_data_path, vocab=cwe_embedding_dict, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:22:26 : loading projection weights from /Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/models/lingala_embeddings_cwe/embedding_50_all_lingala_cwe_corpus.bin\n",
      "19:22:27 : loaded (70404, 100) matrix from /Users/es.py/Projects/Personal/multilingual-drc-news-chatbot/models/lingala_embeddings_cwe/embedding_50_all_lingala_cwe_corpus.bin\n"
     ]
    }
   ],
   "source": [
    "cwe_embedding_model = KeyedVectors.load_word2vec_format(model_cwe_output_data_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bwanya', 0.6193627119064331),\n",
       " ('bososoli', 0.5501773357391357),\n",
       " ('siansi', 0.5497913360595703),\n",
       " ('makambo', 0.5102851390838623),\n",
       " ('bazoba', 0.49367839097976685),\n",
       " ('makanisi', 0.4743432402610779),\n",
       " ('istware', 0.4647260904312134),\n",
       " ('oyo', 0.45812565088272095),\n",
       " ('bafilozofe', 0.4552847146987915),\n",
       " ('filozofi', 0.4538910984992981),\n",
       " ('bioloji', 0.45348161458969116),\n",
       " ('makoki', 0.45278969407081604),\n",
       " ('satinover', 0.4410244822502136),\n",
       " ('likanisi', 0.43894192576408386),\n",
       " ('bongolabongola', 0.43477779626846313),\n",
       " ('rips', 0.43345093727111816),\n",
       " ('finegan', 0.43294334411621094),\n",
       " ('nzokande', 0.4289731979370117),\n",
       " ('pisikoloji', 0.4273372292518616),\n",
       " ('quirke', 0.4267514646053314),\n",
       " ('ete', 0.4220777451992035),\n",
       " ('makesenisaki', 0.4190809726715088),\n",
       " ('gnostiques', 0.4141996502876282),\n",
       " ('mpenzampenza', 0.41356658935546875),\n",
       " ('curtin', 0.4102662205696106)]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwe_embedding_model.most_similar('mayele', topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('luka', 0.601347804069519),\n",
       " ('bakorinti', 0.588614821434021),\n",
       " ('baebre', 0.5854250192642212),\n",
       " ('matai', 0.5801754593849182),\n",
       " ('yoane', 0.5589373111724854),\n",
       " ('mokapo', 0.5534628033638),\n",
       " ('emoniseli', 0.547387957572937),\n",
       " ('marko', 0.5470973253250122),\n",
       " ('baebele', 0.534039318561554),\n",
       " ('bakolinti', 0.5234471559524536),\n",
       " ('nzembo', 0.512860894203186),\n",
       " ('malako', 0.5122451782226562),\n",
       " ('bafilipi', 0.5116504430770874),\n",
       " ('batesaloniki', 0.5111090540885925),\n",
       " ('bagalatia', 0.5006153583526611),\n",
       " ('mazwami', 0.49731481075286865),\n",
       " ('misala', 0.49448102712631226),\n",
       " ('yisaya', 0.49362242221832275),\n",
       " ('elobelami', 0.4762505292892456),\n",
       " ('baverse', 0.47381070256233215),\n",
       " ('malaki', 0.4723062217235565),\n",
       " ('ekolendisa', 0.47178348898887634),\n",
       " ('bakolose', 0.47125673294067383),\n",
       " ('emonisami', 0.4711441993713379),\n",
       " ('talela', 0.47108471393585205)]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('tanga', topn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for now I found that it doesn't have affect on the emdening, we need to make more experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything ,  we need to run the embedding and do some visualization to see how they perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-stuff",
   "language": "python",
   "name": "nlp-stuff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
