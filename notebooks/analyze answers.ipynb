{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.evaluation_utils import compute_f1, compute_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models-predictions-fquad.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5_/n81dq93n79l30d_c34cfqxpr0000gn/T/ipykernel_33517/2553432143.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models-predictions-fquad.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Personal/unsupervised-open-domain-french-question-answering/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Personal/unsupervised-open-domain-french-question-answering/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Personal/unsupervised-open-domain-french-question-answering/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Personal/unsupervised-open-domain-french-question-answering/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Personal/unsupervised-open-domain-french-question-answering/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Personal/unsupervised-open-domain-french-question-answering/.venv/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models-predictions-fquad.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"models-predictions-fquad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5_/n81dq93n79l30d_c34cfqxpr0000gn/T/ipykernel_33517/359752778.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"f1\"] = np.vectorize(compute_f1)(data.prediction, data.goldlabel)\n",
    "data[\"exact\"] = np.vectorize(compute_exact)(data.prediction, data.goldlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>goldlabel</th>\n",
       "      <th>questions</th>\n",
       "      <th>f1</th>\n",
       "      <th>exact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la compression</td>\n",
       "      <td>la compression</td>\n",
       "      <td>question: Qu'est-ce qui réchauffe la substance...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en octobre 1854</td>\n",
       "      <td>octobre 1854</td>\n",
       "      <td>question: Quand est publiée la critique dans l...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>à cause des limites imposées par la fonction d...</td>\n",
       "      <td>à cause des limites imposées par la fonction d...</td>\n",
       "      <td>question: Pourquoi le cheval ailé est-il coupé...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l'association entre syndrome d'Asperger, maladie</td>\n",
       "      <td>l'association entre syndrome d'Asperger, maladie</td>\n",
       "      <td>question: Quelle confusion existe-t-il avec le...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harrison Ford</td>\n",
       "      <td>Harrison Ford</td>\n",
       "      <td>question: Qui est finalement suggéré à Hampton...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prediction  \\\n",
       "0                                     la compression   \n",
       "1                                    en octobre 1854   \n",
       "2  à cause des limites imposées par la fonction d...   \n",
       "3   l'association entre syndrome d'Asperger, maladie   \n",
       "4                                      Harrison Ford   \n",
       "\n",
       "                                           goldlabel  \\\n",
       "0                                     la compression   \n",
       "1                                       octobre 1854   \n",
       "2  à cause des limites imposées par la fonction d...   \n",
       "3   l'association entre syndrome d'Asperger, maladie   \n",
       "4                                      Harrison Ford   \n",
       "\n",
       "                                           questions   f1  exact  \n",
       "0  question: Qu'est-ce qui réchauffe la substance...  1.0      1  \n",
       "1  question: Quand est publiée la critique dans l...  0.8      0  \n",
       "2  question: Pourquoi le cheval ailé est-il coupé...  1.0      1  \n",
       "3  question: Quelle confusion existe-t-il avec le...  1.0      1  \n",
       "4  question: Qui est finalement suggéré à Hampton...  1.0      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499305076387526"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>goldlabel</th>\n",
       "      <th>questions</th>\n",
       "      <th>f1</th>\n",
       "      <th>exact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Théophraste</td>\n",
       "      <td>du maître, mais aussi de l’intendant</td>\n",
       "      <td>question: Qui peut infliger la flagellation ? ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hayden</td>\n",
       "      <td>Ulysses Grant</td>\n",
       "      <td>question: Quel personnalité officialisa la pro...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sur le sol</td>\n",
       "      <td>au fond du puits</td>\n",
       "      <td>question: Où est-ce que gis Stephen ? &lt;/s&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>William Grover-Williams-Caberto</td>\n",
       "      <td>Borzacchini</td>\n",
       "      <td>question: Qui devient le coéquipier de Nuvolar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Cob normand</td>\n",
       "      <td>mareyeur Boulonnais</td>\n",
       "      <td>question: Quelle race autre que le cob est fav...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>Zèbre à Paris</td>\n",
       "      <td>sur différentes scènes nationales et internati...</td>\n",
       "      <td>question: Où Amalric assiste-t-il à des shows ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>L'église est orientée</td>\n",
       "      <td>caractéristique préromane</td>\n",
       "      <td>question: Que caractérise l'emplacement de la ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>imperceptibilité d'interpréter ses propres</td>\n",
       "      <td>Peu diplomates et peu persuas</td>\n",
       "      <td>question: Pourquoi les Asperger éprouvent des ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>la plus complète définition qu'ait jamais donn...</td>\n",
       "      <td>mal social dans son ensemble</td>\n",
       "      <td>question: Que décrit le discours de Dickens d'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>la brucellose peut être éradiquée parmi</td>\n",
       "      <td>vaccination</td>\n",
       "      <td>question: Quelle méthode propose l'APHIS pour ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             prediction  \\\n",
       "11                                          Théophraste   \n",
       "19                                               Hayden   \n",
       "25                                           sur le sol   \n",
       "53                      William Grover-Williams-Caberto   \n",
       "65                                          Cob normand   \n",
       "...                                                 ...   \n",
       "3156                                      Zèbre à Paris   \n",
       "3157                              L'église est orientée   \n",
       "3171         imperceptibilité d'interpréter ses propres   \n",
       "3173  la plus complète définition qu'ait jamais donn...   \n",
       "3180            la brucellose peut être éradiquée parmi   \n",
       "\n",
       "                                              goldlabel  \\\n",
       "11                 du maître, mais aussi de l’intendant   \n",
       "19                                        Ulysses Grant   \n",
       "25                                     au fond du puits   \n",
       "53                                          Borzacchini   \n",
       "65                                  mareyeur Boulonnais   \n",
       "...                                                 ...   \n",
       "3156  sur différentes scènes nationales et internati...   \n",
       "3157                          caractéristique préromane   \n",
       "3171                      Peu diplomates et peu persuas   \n",
       "3173                       mal social dans son ensemble   \n",
       "3180                                        vaccination   \n",
       "\n",
       "                                              questions   f1  exact  \n",
       "11    question: Qui peut infliger la flagellation ? ...  0.0      0  \n",
       "19    question: Quel personnalité officialisa la pro...  0.0      0  \n",
       "25           question: Où est-ce que gis Stephen ? </s>  0.0      0  \n",
       "53    question: Qui devient le coéquipier de Nuvolar...  0.0      0  \n",
       "65    question: Quelle race autre que le cob est fav...  0.0      0  \n",
       "...                                                 ...  ...    ...  \n",
       "3156  question: Où Amalric assiste-t-il à des shows ...  0.0      0  \n",
       "3157  question: Que caractérise l'emplacement de la ...  0.0      0  \n",
       "3171  question: Pourquoi les Asperger éprouvent des ...  0.0      0  \n",
       "3173  question: Que décrit le discours de Dickens d'...  0.0      0  \n",
       "3180  question: Quelle méthode propose l'APHIS pour ...  0.0      0  \n",
       "\n",
       "[472 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.f1 ==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.questions = data.questions.str.replace(\"question:\", \"\").str.replace(\"</s>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"question_type\"] = data.questions.str.strip().str.split(\" \").apply(lambda x: x[0].lower())\n",
    "data[\"answer_length\"] = data.goldlabel.str.split(\" \").apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_prepositions = [\"combien\",\"quand\", \"qui\", \"quelle\", \"que\", \"pourquoi\", \"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qui         380\n",
       "quelle      296\n",
       "que         250\n",
       "quand       186\n",
       "comment     168\n",
       "combien     154\n",
       "pourquoi     63\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"question_type\"].value_counts().loc[question_prepositions].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_type_count = data[\"question_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['quel', 'qui', 'quelle', 'que', 'quand', 'comment', 'combien', 'de', 'où', 'dans', 'à', \"qu'est-ce\", 'a', 'quels', 'pourquoi', 'quelles', 'par', \"qu'est\", 'en', 'sur', 'pour', 'avec', 'selon', \"d'où\", 'depuis', 'lors'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_type_count.loc[question_type_count.values >=10].to_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_type'] = np.where(data['question_type'].isin(question_type_count.loc[question_type_count.values >=10].to_dict().keys()), data['question_type'], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group_question = data.groupby('question_type').agg({'f1': 'mean', 'exact': 'mean', \"prediction\": \"count\", \"answer_length\": \"mean\"}).rename({\"prediction\": \"count\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>exact</th>\n",
       "      <th>count</th>\n",
       "      <th>answer_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>combien</th>\n",
       "      <td>0.801479</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>154</td>\n",
       "      <td>2.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depuis</th>\n",
       "      <td>0.766162</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>12</td>\n",
       "      <td>2.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qui</th>\n",
       "      <td>0.853524</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>380</td>\n",
       "      <td>2.444737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quand</th>\n",
       "      <td>0.800437</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>186</td>\n",
       "      <td>2.720430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lors</th>\n",
       "      <td>0.809048</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quel</th>\n",
       "      <td>0.737137</td>\n",
       "      <td>0.588764</td>\n",
       "      <td>445</td>\n",
       "      <td>3.080899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quelle</th>\n",
       "      <td>0.769003</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>296</td>\n",
       "      <td>3.101351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d'où</th>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>19</td>\n",
       "      <td>3.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.774930</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>71</td>\n",
       "      <td>3.183099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.765955</td>\n",
       "      <td>0.623288</td>\n",
       "      <td>146</td>\n",
       "      <td>3.184932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>41</td>\n",
       "      <td>3.268293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avec</th>\n",
       "      <td>0.851335</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>30</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dans</th>\n",
       "      <td>0.689517</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>123</td>\n",
       "      <td>3.390244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>où</th>\n",
       "      <td>0.728784</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>131</td>\n",
       "      <td>3.442748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par</th>\n",
       "      <td>0.772192</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>50</td>\n",
       "      <td>3.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.365591</td>\n",
       "      <td>93</td>\n",
       "      <td>3.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment</th>\n",
       "      <td>0.719082</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>168</td>\n",
       "      <td>3.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sur</th>\n",
       "      <td>0.687432</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>38</td>\n",
       "      <td>3.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qu'est</th>\n",
       "      <td>0.726143</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>50</td>\n",
       "      <td>3.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.699164</td>\n",
       "      <td>0.477987</td>\n",
       "      <td>159</td>\n",
       "      <td>4.132075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pour</th>\n",
       "      <td>0.750568</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>34</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qu'est-ce</th>\n",
       "      <td>0.738804</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>88</td>\n",
       "      <td>4.965909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quels</th>\n",
       "      <td>0.739180</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>71</td>\n",
       "      <td>4.971831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quelles</th>\n",
       "      <td>0.742540</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>52</td>\n",
       "      <td>5.134615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>que</th>\n",
       "      <td>0.683702</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>250</td>\n",
       "      <td>5.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selon</th>\n",
       "      <td>0.766771</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>27</td>\n",
       "      <td>5.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pourquoi</th>\n",
       "      <td>0.675281</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>63</td>\n",
       "      <td>6.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     f1     exact  count  answer_length\n",
       "question_type                                          \n",
       "combien        0.801479  0.655844    154       2.090909\n",
       "depuis         0.766162  0.416667     12       2.333333\n",
       "qui            0.853524  0.794737    380       2.444737\n",
       "quand          0.800437  0.596774    186       2.720430\n",
       "lors           0.809048  0.500000     10       3.000000\n",
       "quel           0.737137  0.588764    445       3.080899\n",
       "quelle         0.769003  0.587838    296       3.101351\n",
       "d'où           0.705263  0.684211     19       3.157895\n",
       "a              0.774930  0.605634     71       3.183099\n",
       "de             0.765955  0.623288    146       3.184932\n",
       "en             0.769841  0.560976     41       3.268293\n",
       "avec           0.851335  0.600000     30       3.300000\n",
       "dans           0.689517  0.414634    123       3.390244\n",
       "où             0.728784  0.442748    131       3.442748\n",
       "par            0.772192  0.560000     50       3.460000\n",
       "à              0.580645  0.365591     93       3.516129\n",
       "comment        0.719082  0.517857    168       3.547619\n",
       "sur            0.687432  0.342105     38       3.631579\n",
       "qu'est         0.726143  0.580000     50       3.660000\n",
       "Other          0.699164  0.477987    159       4.132075\n",
       "pour           0.750568  0.529412     34       4.500000\n",
       "qu'est-ce      0.738804  0.568182     88       4.965909\n",
       "quels          0.739180  0.591549     71       4.971831\n",
       "quelles        0.742540  0.576923     52       5.134615\n",
       "que            0.683702  0.496000    250       5.312000\n",
       "selon          0.766771  0.444444     27       5.851852\n",
       "pourquoi       0.675281  0.317460     63       6.555556"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group_question.sort_values(by=['answer_length', \"f1\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>goldlabel</th>\n",
       "      <th>questions</th>\n",
       "      <th>f1</th>\n",
       "      <th>exact</th>\n",
       "      <th>question_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prediction, goldlabel, questions, f1, exact, question_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.question_type.str.lower() == \"Quoi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = pd.read_csv(current_working_directory.joinpath(\"experiments-resulsts.csv\"),\n",
    "                          usecols=[\"f1_score\", \"exact_matches\", \"Name\", \"Start Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>exact_matches</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-05 13:19:35</td>\n",
       "      <td>one-paragraph-piaf-multi-context</td>\n",
       "      <td>27.744833</td>\n",
       "      <td>45.604458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-05 13:04:28</td>\n",
       "      <td>one-pragraph-piaf-with-context</td>\n",
       "      <td>38.956974</td>\n",
       "      <td>55.874863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-05 12:44:44</td>\n",
       "      <td>one-paragraph-piaf-bm25</td>\n",
       "      <td>27.744833</td>\n",
       "      <td>45.604458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-05 12:35:48</td>\n",
       "      <td>one-prarragrah-fquad-bm25</td>\n",
       "      <td>54.673779</td>\n",
       "      <td>72.963928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-05 12:17:22</td>\n",
       "      <td>one-paragraph-fquad-valid</td>\n",
       "      <td>54.673779</td>\n",
       "      <td>72.963928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-08-05 12:09:23</td>\n",
       "      <td>one-pragraph-valid-fquad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-08-04 19:37:17</td>\n",
       "      <td>two-paragraph-piaf-base-questions</td>\n",
       "      <td>86.571053</td>\n",
       "      <td>91.426132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-08-04 19:17:24</td>\n",
       "      <td>two-paragraph-piaf-base-questions</td>\n",
       "      <td>86.571053</td>\n",
       "      <td>91.426132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-08-04 18:52:02</td>\n",
       "      <td>two-paragraph-piaf-additional-questions</td>\n",
       "      <td>35.489666</td>\n",
       "      <td>53.667488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-08-04 18:42:51</td>\n",
       "      <td>two-paragraph-fquad-with-multi-contexts-with-e...</td>\n",
       "      <td>57.685070</td>\n",
       "      <td>75.614594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-08-04 18:35:14</td>\n",
       "      <td>two-paragraph-fquad-with-multi-contexts-with-e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start Time                                               Name  \\\n",
       "0   2022-08-05 13:19:35                   one-paragraph-piaf-multi-context   \n",
       "1   2022-08-05 13:04:28                     one-pragraph-piaf-with-context   \n",
       "2   2022-08-05 12:44:44                            one-paragraph-piaf-bm25   \n",
       "3   2022-08-05 12:35:48                          one-prarragrah-fquad-bm25   \n",
       "4   2022-08-05 12:17:22                          one-paragraph-fquad-valid   \n",
       "5   2022-08-05 12:09:23                           one-pragraph-valid-fquad   \n",
       "6   2022-08-04 19:37:17                  two-paragraph-piaf-base-questions   \n",
       "7   2022-08-04 19:17:24                  two-paragraph-piaf-base-questions   \n",
       "8   2022-08-04 18:52:02            two-paragraph-piaf-additional-questions   \n",
       "9   2022-08-04 18:42:51  two-paragraph-fquad-with-multi-contexts-with-e...   \n",
       "10  2022-08-04 18:35:14  two-paragraph-fquad-with-multi-contexts-with-e...   \n",
       "\n",
       "    exact_matches   f1_score  \n",
       "0       27.744833  45.604458  \n",
       "1       38.956974  55.874863  \n",
       "2       27.744833  45.604458  \n",
       "3       54.673779  72.963928  \n",
       "4       54.673779  72.963928  \n",
       "5             NaN        NaN  \n",
       "6       86.571053  91.426132  \n",
       "7       86.571053  91.426132  \n",
       "8       35.489666  53.667488  \n",
       "9       57.685070  75.614594  \n",
       "10            NaN        NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments.sort_values(\"Start Time\", ascending=False).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "gcloud compute scp  --recurse data/corpus/french-qa/{fquad-with-multi-context-with-without-answer,piaf-additional-with-from-wikipedia-bm25} lafand-mt:/home/es.py/school_stuff/unsupervised-open-domain-french-question-answering/data/processed/french-qa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "6e18561f9b3508842a7e27c31e07753b72154ec003d59bf44fbebcfef9c0c06c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
